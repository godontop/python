{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'焉'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\u7109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28937"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0x7109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'焉'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u7109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'焉'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u7109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('\\u7109')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "a = '\\u7109'\n",
    "b = u'\\u7109'\n",
    "c = b'\\u7109'\n",
    "print(type(a))\n",
    "print(type(b))\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "焉\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u7109')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "焉\n"
     ]
    }
   ],
   "source": [
    "print('\\u7109')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28937"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('焉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x7109'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(28937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'焉'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u7109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'javascript-frameworks': ['jQuery', 'Modernizr', 'jQuery UI'],\n",
       " 'programming-languages': ['Python'],\n",
       " 'web-frameworks': ['Web2py', 'Twitter Bootstrap'],\n",
       " 'web-servers': ['Nginx']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import builtwith\n",
    "builtwith.parse('http://example.webscraping.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.1\n",
      "2\n",
      "1.2100000000000002\n",
      "3\n",
      "1.3310000000000004\n",
      "4\n",
      "1.4641000000000004\n",
      "5\n",
      "1.6105100000000006\n",
      "6\n",
      "1.7715610000000008\n",
      "7\n",
      "1.9487171000000012\n",
      "8\n",
      "2.1435888100000016\n",
      "9\n",
      "2.357947691000002\n",
      "10\n",
      "2.5937424601000023\n",
      "11\n",
      "2.8531167061100025\n",
      "12\n",
      "3.138428376721003\n",
      "13\n",
      "3.452271214393104\n",
      "14\n",
      "3.7974983358324144\n",
      "15\n",
      "4.177248169415656\n",
      "16\n",
      "4.594972986357222\n",
      "17\n",
      "5.054470284992945\n",
      "18\n",
      "5.55991731349224\n",
      "19\n",
      "6.115909044841464\n",
      "20\n",
      "6.727499949325611\n",
      "21\n",
      "7.400249944258173\n",
      "22\n",
      "8.14027493868399\n",
      "23\n",
      "8.95430243255239\n",
      "24\n",
      "9.84973267580763\n",
      "25\n",
      "10.834705943388395\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 100):\n",
    "    print(i)\n",
    "    print(pow(1.1, i))\n",
    "    if pow(1.1, i) > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"APPSPOT.COM\",\n",
      "    \"appspot.com\"\n",
      "  ],\n",
      "  \"registrar\": \"MarkMonitor, Inc.\",\n",
      "  \"whois_server\": \"whois.markmonitor.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": [\n",
      "    \"2018-02-06 10:30:28\",\n",
      "    \"2018-02-06 02:30:29\"\n",
      "  ],\n",
      "  \"creation_date\": [\n",
      "    \"2005-03-10 02:27:55\",\n",
      "    \"2005-03-09 18:27:55\"\n",
      "  ],\n",
      "  \"expiration_date\": [\n",
      "    \"2019-03-10 01:27:55\",\n",
      "    \"2019-03-09 00:00:00\"\n",
      "  ],\n",
      "  \"name_servers\": [\n",
      "    \"NS1.GOOGLE.COM\",\n",
      "    \"NS2.GOOGLE.COM\",\n",
      "    \"NS3.GOOGLE.COM\",\n",
      "    \"NS4.GOOGLE.COM\",\n",
      "    \"ns2.google.com\",\n",
      "    \"ns3.google.com\",\n",
      "    \"ns4.google.com\",\n",
      "    \"ns1.google.com\"\n",
      "  ],\n",
      "  \"status\": [\n",
      "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "    \"clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\",\n",
      "    \"serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\",\n",
      "    \"serverTransferProhibited https://icann.org/epp#serverTransferProhibited\",\n",
      "    \"serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\",\n",
      "    \"clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)\",\n",
      "    \"clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)\",\n",
      "    \"clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)\",\n",
      "    \"serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)\",\n",
      "    \"serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)\",\n",
      "    \"serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)\"\n",
      "  ],\n",
      "  \"emails\": [\n",
      "    \"abusecomplaints@markmonitor.com\",\n",
      "    \"dns-admin@google.com\"\n",
      "  ],\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": \"Domain Administrator\",\n",
      "  \"org\": \"Google LLC\",\n",
      "  \"address\": \"1600 Amphitheatre Parkway,\",\n",
      "  \"city\": \"Mountain View\",\n",
      "  \"state\": \"CA\",\n",
      "  \"zipcode\": \"94043\",\n",
      "  \"country\": \"US\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import whois\n",
    "\n",
    "\n",
    "print(whois.whois('appspot.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"LIAOXUEFENG.COM\",\n",
      "    \"liaoxuefeng.com\"\n",
      "  ],\n",
      "  \"registrar\": \"HiChina Zhicheng Technology Ltd.\",\n",
      "  \"whois_server\": \"grs-whois.hichina.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": \"2017-11-14 08:27:15\",\n",
      "  \"creation_date\": \"2009-02-05 01:51:44\",\n",
      "  \"expiration_date\": \"2019-02-05 01:51:44\",\n",
      "  \"name_servers\": [\n",
      "    \"F1G1NS1.DNSPOD.NET\",\n",
      "    \"F1G1NS2.DNSPOD.NET\"\n",
      "  ],\n",
      "  \"status\": \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "  \"emails\": [\n",
      "    \"DomainAbuse@service.aliyun.com\",\n",
      "    \"askxuefeng@gmail.com\"\n",
      "  ],\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": \"LIAO XUE FENG\",\n",
      "  \"org\": \"LIAO XUE FENG\",\n",
      "  \"address\": \"No.213, HUA JIA DI XI LI, CHAO YANG\",\n",
      "  \"city\": \"BEIJING\",\n",
      "  \"state\": \"BEIJING\",\n",
      "  \"zipcode\": \"100102\",\n",
      "  \"country\": \"CN\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import whois\n",
    "\n",
    "\n",
    "print(whois.whois('liaoxuefeng.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    return urlib.request.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\r\\n<html>\\r\\n\\t<head>\\r\\n\\t\\t<meta charset=\"gb2312\">\\r\\n\\t\\t<meta name=\"mobile-agent\" content=\"format=html5; url=http://m.ip138.com/\">\\r\\n\\t\\t<title>IP\\xb5\\xd8\\xd6\\xb7\\xb2\\xe9\\xd1\\xaf--\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc2\\xeb\\xb2\\xe9\\xd1\\xaf\\xb9\\xe9\\xca\\xf4\\xb5\\xd8 | \\xd3\\xca\\xd5\\xfe\\xb1\\xe0\\xc2\\xeb\\xb2\\xe9\\xd1\\xaf | \\xb3\\xa4\\xcd\\xbe\\xb5\\xe7\\xbb\\xb0\\xc7\\xf8\\xba\\xc5 | \\xc9\\xed\\xb7\\xdd\\xd6\\xa4\\xba\\xc5\\xc2\\xeb\\xd1\\xe9\\xd6\\xa4\\xd4\\xda\\xcf\\xdf\\xb2\\xe9\\xd1\\xaf\\xcd\\xf8</title>\\r\\n\\t\\t<meta name=\"keywords\" content=\"ip,IP\\xb2\\xe9\\xd1\\xaf,IP\\xb5\\xd8\\xd6\\xb7\\xb2\\xe9\\xd1\\xaf,ip138\"/>\\r\\n\\t\\t<meta name=\"description\" content=\"ip,IP\\xb2\\xe9\\xd1\\xaf,IP\\xb5\\xd8\\xd6\\xb7\\xb2\\xe9\\xd1\\xaf,ip138\"/>\\r\\n\\t\\t<script type=\"text/javascript\">\\r\\n\\t\\t\\t<!--\\r\\n\\t\\t\\t\\tif(window.top!=window.self)window.top.location.href=\\'http://www.ip138.com/\\';\\r\\n\\t\\t\\t//-->\\r\\n\\t\\t</script>\\r\\n\\t\\t<style type=\"text/css\">\\r\\n\\t\\t\\thtml{color:#000;background:#FFF}body,div,dl,dt,dd,ul,ol,li,h1,h3,h3,h4,h5,h6,pre,code,form,fieldset,legend,input,textarea,p,blockquote,th,td{margin:0;padding:0}table{border-collapse:collapse;border-spacing:0}fieldset,img{border:0}address,caption,cite,code,dfn,em,strong,th,var{font-style:normal;font-weight:normal}ol,ul{list-style:none}caption,th{text-align:left}h1,h3,h3,h4,h5,h6{font-size:100%;}q:before,q:after{content:\\'\\'}abbr,acronym{border:0;font-variant:normal}sup{vertical-align:text-top}sub{vertical-align:text-bottom}input,textarea,select{font-family:inherit;font-size:inherit;font-weight:inherit;*font-size:100%}legend{color:#000}\\r\\n\\t\\t\\thtml{height:100%;}\\r\\n\\t\\t\\tbody{height:100%;font-size:14px;font-family: Arial,Helvetica,\"Microsoft Yahei\";color:#333;}\\r\\n\\t\\t\\ttable{table-layout:fixed;border-collapse: collapse;border-spacing: 0;margin: 0 auto;}\\r\\n\\t\\t\\tinput,button{font-family: Tahoma,Arial, Helvetica,\"Microsoft Yahei\";}\\r\\n\\t\\t\\ta{color: #1c5f82;text-decoration: none}\\r\\n\\t\\t\\ta:hover{color: #cc5533;text-decoration: underline;}\\r\\n\\t\\t\\t.wrapper{width: 960px;margin: 0 auto;}\\r\\n\\t\\t\\t.module{margin-bottom:15px;text-align: center;}\\r\\n\\t\\t\\t.red{color: red}\\r\\n\\t\\t\\t.blue{color: blue}\\r\\n\\t\\t\\t.small{font-size: smaller;}\\r\\n\\r\\n\\t\\t\\t.mod-header{height:48px;background:#69c;line-height:48px;margin-bottom: 5px;}\\r\\n\\t\\t\\t.mod-header h1,.mod-header h2{margin:0 20px;line-height: 48px;font-size: 16px;color: #fff;}\\r\\n\\t\\t\\t.mod-guide table{font-size: 16px;}\\r\\n\\t\\t\\t.mod-guide td{border:1px solid #eee;line-height: 30px;}\\r\\n\\t\\t\\t.mod-guide span{font-weight: bold;color: #008000;}\\r\\n\\t\\t\\t.mod-ip{margin-bottom: 15px;}\\r\\n\\t\\t\\t.mod-ip h3{line-height: 36px;font-size:18px;}\\r\\n\\t\\t\\t.mod-ip iframe{width: 100%;margin-bottom:7px;height: 26px; padding: 5px 0;}\\r\\n\\t\\t\\t.mod-ip p{line-height: 26px;font-size: 16px;}\\r\\n\\t\\t\\t.mod-ip p a{margin:0 7px;}\\r\\n\\t\\t\\t.mod-ip form p{line-height: 30px;}\\r\\n\\t\\t\\t.mod-explain{margin-bottom:30px;line-height: 22px;}\\r\\n\\t\\t\\t.mod-explain h3{font-weight: normal;font-size: 16px;}\\r\\n\\t\\t\\t.mod-explain a{margin: 0 7px;}\\r\\n\\t\\t\\t.mod-form caption{position: relative;top: 1px;background: #69c;line-height:32px;text-align: center;color: #1c5f82;*zoom:1;}\\r\\n\\t\\t\\t.mod-form .title{text-decoration: none;font-size:16px;color: #fff;}\\r\\n\\t\\t\\t.mod-form .more:hover{color: #1c5f82;}\\r\\n\\t\\t\\t.mod-form td,.mod-form th{height: 32px;border: 1px solid #ccc;line-height: 32px;font-family:Tahoma;}\\r\\n\\t\\t\\t.mod-form th{text-align: center;}\\r\\n\\t\\t\\t.mod-form p{line-height:32px;}\\r\\n\\t\\t\\t.mod-form p a{margin: 0 12px;}\\r\\n\\t\\t\\t.mod-form label{padding: 0 4px;vertical-align: middle;}\\r\\n\\t\\t\\t.mod-form .input,.mod-ip .input{width:130px;height: 20px;padding:2px 5px;border: 1px solid #bdbdbd;line-height: 20px;text-indent: 5px;font-size: 14px;vertical-align: middle;position:relative;_top:-1px;}\\r\\n\\t\\t\\t.mod-form .btn,.mod-ip .btn{height: 24px;padding: 0 10px;cursor: pointer;line-height:24px;vertical-align: middle;font-size: 12px;line-height:16px\\\\0;_line-height:16px;outline:0;}\\r\\n\\t\\t\\t.mod-form strong a{font-weight:bold;color:#008000;}\\r\\n\\t\\t\\t.mod-link{padding:30px 30px 0;line-height: 24px;text-align: center;}\\r\\n\\t\\t\\t.mod-link a{margin:0 3px;white-space: nowrap;}\\r\\n\\t\\t\\t.mod-friendlink{width:750px;margin: 0 auto 15px;padding: 5px;border: 1px solid #008000;line-height: 24px;text-align: center;}\\r\\n\\t\\t\\t.mod-friendlink a{white-space: nowrap;margin:0 3px;}\\r\\n\\t\\t\\t.mod-foot{margin-top:30px;padding:20px 0;line-height: 24px;text-align: center;}\\r\\n\\t\\t\\t.mod-foot a{margin:0 5px;}\\r\\n\\t\\t\\t.module .large-input{width: 200px;}\\r\\n\\t\\t\\tinput[type=number] {-moz-appearance:textfield;}\\r\\n\\t\\t\\t::-webkit-inner-spin-button,::-webkit-outer-spin-button{display: none;}\\r\\n\\t\\t</style>\\r\\n\\t</head>\\r\\n\\t<body>\\r\\n\\t\\t<div class=\"wrapper\">\\r\\n\\t\\t\\t<div class=\"module mod-header\">\\r\\n\\t\\t\\t\\t<table width=\"100%\">\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td align=\"left\">\\r\\n\\t\\t\\t\\t\\t\\t\\t<h1>www.ip138.com \\xb2\\xe9\\xd1\\xaf\\xcd\\xf8</h1>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td align=\"right\">\\r\\n\\t\\t\\t\\t\\t\\t\\t<h2>\\xca\\xd6\\xbb\\xfa\\xc9\\xcf\\xcd\\xf8\\xb2\\xe9\\xd1\\xaf:m.ip138.com</h2>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t</table>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-guide\">\\r\\n\\t\\t\\t\\t<table width=\"100%\">\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/weather/\" target=\"_blank\">\\xcc\\xec\\xc6\\xf8\\xd4\\xa4\\xb1\\xa8-\\xd4\\xa4\\xb1\\xa8\\xce\\xe5\\xcc\\xec</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/train/\" target=\"_blank\">\\xb9\\xfa\\xc4\\xda\\xc1\\xd0\\xb3\\xb5\\xca\\xb1\\xbf\\xcc\\xb1\\xed\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/sj/\" target=\"_blank\">\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc2\\xeb\\xcb\\xf9\\xd4\\xda\\xb5\\xd8\\xc7\\xf8\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/day/\" target=\"_blank\">\\xd2\\xf5\\xd1\\xf4\\xd7\\xaa\\xbb\\xbb\\xcd\\xf2\\xc4\\xea\\xc0\\xfa</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/gb.htm\" target=\"_blank\">\\xba\\xba\\xd7\\xd6\\xbc\\xf2\\xcc\\xe5\\xb7\\xb1\\xcc\\xe5\\xd7\\xaa\\xbb\\xbb</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/jb.htm\" target=\"_blank\">\\xb9\\xfa\\xc4\\xda\\xb9\\xfa\\xbc\\xca\\xbb\\xfa\\xc6\\xb1\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://10.ip138.com/\" target=\"_blank\">\\xc6\\xb7\\xc5\\xc6\\xc5\\xc5\\xd0\\xd0\\xb0\\xf1</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/wb/wb.asp\" target=\"_blank\">\\xce\\xe5\\xb1\\xca\\xb1\\xe0\\xc2\\xeb\\xc6\\xb4\\xd2\\xf4\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/tran.htm\" target=\"_blank\">\\xd4\\xda\\xcf\\xdf\\xb7\\xad\\xd2\\xeb</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/hl.asp\" target=\"_blank\">\\xbb\\xf5\\xb1\\xd2\\xbb\\xe3\\xc2\\xca</a>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/zt.htm\" target=\"_blank\">\\xd7\\xaa\\xcc\\xf9\\xb9\\xa4\\xbe\\xdf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/converter.htm\" target=\"_blank\">\\xd4\\xda\\xcf\\xdf\\xb6\\xc8\\xba\\xe2\\xc1\\xbf\\xd7\\xaa\\xbb\\xbb\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/post/\" target=\"_blank\">\\xd3\\xca\\xb1\\xe0\\xb2\\xe9\\xd1\\xaf\\xc7\\xf8\\xba\\xc5\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://qq.ip138.com/idsearch/\" target=\"_blank\">\\xc9\\xed\\xb7\\xdd\\xd6\\xa4\\xba\\xc5\\xc2\\xeb\\xb2\\xe9\\xd1\\xaf\\xd1\\xe9\\xd6\\xa4</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/ems/\" target=\"_blank\">\\xbf\\xec\\xb5\\xdd\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/ems/\" target=\"_blank\">EMS\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/carlist.htm\" target=\"_blank\">\\xc8\\xab\\xb9\\xfa\\xb8\\xf7\\xb5\\xd8\\xb3\\xb5\\xc5\\xc6\\xb2\\xe9\\xd1\\xaf\\xb1\\xed</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/weizhang.htm\" target=\"_blank\">\\xb3\\xb5\\xc1\\xbe\\xbd\\xbb\\xcd\\xa8\\xce\\xa5\\xd5\\xc2\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t</table>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-ip\">\\r\\n\\t\\t\\t\\t<h3>www.ip138.com iP\\xb2\\xe9\\xd1\\xaf(\\xcb\\xd1\\xcb\\xf7iP\\xb5\\xd8\\xd6\\xb7\\xb5\\xc4\\xb5\\xd8\\xc0\\xed\\xce\\xbb\\xd6\\xc3)</h3>\\r\\n\\t\\t\\t\\t<iframe src=\"http://2017.ip138.com/ic.asp\" rel=\"nofollow\" frameborder=\"0\" scrolling=\"no\"></iframe>\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/kuandai/ruzhu.htm\" target=\"_blank\">\\xbf\\xed\\xb4\\xf8\\xb0\\xb2\\xd7\\xb0\\xca\\xa6\\xb8\\xb5\\xc9\\xea\\xc7\\xeb\\xc8\\xeb\\xd7\\xa4</a>\\r\\n\\t\\t\\t\\t\\t<span>|</span>\\r\\n\\t\\t\\t\\t\\t<a class=\"red\" href=\"http://www.gaosu.com/\" target=\"_blank\">it\\xca\\xd7\\xd2\\xb3</a>\\r\\n\\t\\t\\t\\t\\t<span>|</span>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/idc/\" target=\"_blank\">idc\\xb9\\xab\\xcb\\xbe\\xb4\\xf3\\xc8\\xab</a>\\r\\n\\t\\t\\t\\t\\t<span>|</span>\\r\\n\\t\\t\\t\\t\\t<a class=\"red\" href=\"http://user.ip138.com/ip/lib/\" target=\"_blank\">\\xc0\\xeb\\xcf\\xdfiP\\xca\\xfd\\xbe\\xdd\\xbf\\xe2</a>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t\\t<form method=\"get\" action=\"ips138.asp\" target=\"_blank\" name=\"ipform\">\\r\\n\\t\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t\\t\\xd4\\xda\\xcf\\xc2\\xc3\\xe6\\xca\\xe4\\xc8\\xeb\\xbf\\xf2\\xd6\\xd0\\xca\\xe4\\xc8\\xeb\\xc4\\xfa\\xd2\\xaa\\xb2\\xe9\\xd1\\xaf\\xb5\\xc4iP\\xb5\\xd8\\xd6\\xb7\\xbb\\xf2\\xd5\\xdf\\xd3\\xf2\\xc3\\xfb\\xa3\\xac\\xb5\\xe3\\xbb\\xf7\\xb2\\xe9\\xd1\\xaf\\xb0\\xb4\\xc5\\xa5\\xbc\\xb4\\xbf\\xc9\\xb2\\xe9\\xd1\\xaf\\xb8\\xc3iP\\xcb\\xf9\\xca\\xf4\\xb5\\xc4\\xc7\\xf8\\xd3\\xf2\\xa1\\xa3\\r\\n\\t\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t\\t<label for=\"ip\">iP\\xb5\\xd8\\xd6\\xb7\\xbb\\xf2\\xd5\\xdf\\xd3\\xf2\\xc3\\xfb</label>\\r\\n\\t\\t\\t\\t\\t\\t<input class=\"input large-input\" id=\"ip\" type=\"text\" name=\"ip\" size=\"16\"/>\\r\\n\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"2\"/>\\r\\n\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" value=\"\\xb2\\xe9\\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t<a class=\"red\" href=\"http://user.ip138.com/ip/\" target=\"_blank\">iP\\xb2\\xe9\\xd1\\xaf\\xbd\\xd3\\xbf\\xda</a>\\r\\n\\t\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-explain\">\\r\\n\\t\\t\\t\\t<h3>iP138\\xd7\\xa8\\xd2\\xb57*24\\xd0\\xa1\\xca\\xb1\\xce\\xaa\\xc4\\xfa\\xb7\\xfe\\xce\\xf1</h3>\\r\\n\\t\\t\\t\\t<p>\\xd7\\xa2:\\xb1\\xbe\\xd5\\xbe\\xb5\\xc4iP\\xca\\xfd\\xbe\\xdd\\xbf\\xe2\\xce\\xaa\\xd7\\xee\\xd0\\xc2\\xb5\\xc4\\xca\\xfd\\xbe\\xdd\\xbf\\xe2,\\xc3\\xbf\\xd6\\xdc\\xd7\\xd4\\xb6\\xaf\\xb8\\xfc\\xd0\\xc2\\xd2\\xbb\\xb4\\xce</p>\\r\\n\\t\\t\\t\\t<p><a href=\"iplink.htm\" rel=\"nofollow\" target=\"_blank\">\\xbb\\xb6\\xd3\\xad\\xb8\\xf7\\xcd\\xf8\\xd5\\xbe\\xc1\\xb4\\xbd\\xd3\\xb1\\xbe\\xd5\\xbeiP\\xca\\xfd\\xbe\\xdd\\xbf\\xe2,\\xbb\\xf1\\xc8\\xa1\\xb4\\xfa\\xc2\\xeb\\xb0\\xb4\\xb4\\xcb</a></p>\\r\\n\\t\\t\\t\\t<p>\\xc8\\xe7\\xb7\\xa2\\xcf\\xd6\\xd0\\xa1\\xb2\\xbf\\xb7\\xd6iP\\xb2\\xe9\\xd1\\xaf\\xbd\\xe1\\xb9\\xfb\\xb2\\xbb\\xd5\\xfd\\xc8\\xb7\\xc7\\xeb\\xb5\\xbd\\xb9\\xd9\\xb7\\xbd\\xcd\\xf8\\xd5\\xbe<a href=\"http://www.apnic.net/\" rel=\"nofollow\" target=\"_blank\">http://www.apnic.net</a>\\xb2\\xe9\\xd1\\xaf,\\xd2\\xd4apnic\\xce\\xaa\\xd7\\xbc\\xa1\\xa3</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-form\">\\r\\n\\t\\t\\t\\t<table width=\"80%\">\\r\\n\\t\\t\\t\\t\\t<caption><span class=\"title\">\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc2\\xeb\\xcb\\xf9\\xd4\\xda\\xb5\\xd8\\xc7\\xf8\\xc7\\xbf\\xc1\\xa6\\xb2\\xe9\\xd1\\xaf</span></caption>\\r\\n\\t\\t\\t\\t\\t<tr><th>\\xca\\xe4\\xc8\\xeb\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xbc\\xb4\\xbf\\xc9\\xd6\\xaa\\xb5\\xc0\\xd3\\xc3\\xbb\\xa7\\xcb\\xf9\\xd4\\xda\\xb5\\xc4\\xb5\\xd8\\xc7\\xf8</th></tr>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"http://www.ip138.com:8080/search.asp\" method=\"get\" target=\"mobilewindow\" name=\"mobileform\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label for=\"mobile\">\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc2\\xeb\\xa3\\xa8\\xb6\\xce\\xa3\\xa9</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input large-input\" id=\"mobile\" type=\"number\" name=\"mobile\" maxlength=\"11\" size=\"15\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"mobile\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" value=\"\\xb2\\xe9\\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<a id=\"luck\" href=\"http://jx.ip138.com/\" target=\"_blank\">\\xb2\\xe2\\xbc\\xaa\\xd0\\xd7</a>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t</table>\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.ip138.com/sjlink.htm\" rel=\"nofollow\" target=\"_blank\">\\xbb\\xb6\\xd3\\xad\\xb8\\xf7\\xcd\\xf8\\xd5\\xbe\\xc3\\xe2\\xb7\\xd1\\xc1\\xb4\\xbd\\xd3\\xb1\\xbe\\xd5\\xbe\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc2\\xeb\\xb2\\xe9\\xd1\\xaf\\xcf\\xb5\\xcd\\xb3,\\xbb\\xf1\\xc8\\xa1\\xb4\\xfa\\xc2\\xeb\\xb0\\xb4\\xb4\\xcb</a>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-form\">\\r\\n\\t\\t\\t\\t<table width=\"80%\">\\r\\n\\t\\t\\t\\t\\t<caption>\\r\\n\\t\\t\\t\\t\\t\\t<a class=\"title\" href=\"http://www.ip138.com/post/\" target=\"_blank\">\\xb9\\xfa\\xc4\\xda\\xd3\\xca\\xd5\\xfe\\xb1\\xe0\\xc2\\xeb\\xba\\xcd\\xb3\\xa4\\xcd\\xbe\\xb5\\xe7\\xbb\\xb0\\xc7\\xf8\\xba\\xc5\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t(<a class=\"more\" href=\"http://www.ip138.com/post/\" target=\"_blank\" rel=\"nofollow\">\\xb8\\xfc\\xcf\\xea\\xcf\\xb8\\xb5\\xc4\\xb9\\xa6\\xc4\\xdc\\xb0\\xb4\\xb4\\xcb</a>)\\r\\n\\t\\t\\t\\t\\t</caption>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"/post/search.asp\" method=\"get\" name=\"area2zipForm\" target=\"searchwindow\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label>\\xb5\\xd8\\xc3\\xfb\\xb2\\xe9\\xd1\\xaf\\xd3\\xca\\xb1\\xe0</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input\" type=\"text\" name=\"area\" size=\"16\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"area2zip\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" name=\"B1\" value=\"\\xb2\\xe9 \\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"/post/search.asp\" method=\"get\" name=\"zipform\" target=\"searchwindow\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label>\\xd3\\xca\\xb1\\xe0\\xb2\\xe9\\xd1\\xaf\\xb5\\xd8\\xc3\\xfb</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input\" type=\"number\" name=\"zip\" size=\"10\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"zip2area\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" name=\"B1\" value=\"\\xb2\\xe9 \\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"/post/search.asp\" method=\"get\" name=\"area2zoneForm\" target=\"searchwindow\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label>\\xb5\\xd8\\xc3\\xfb\\xb2\\xe9\\xd1\\xaf\\xc7\\xf8\\xba\\xc5</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input\" type=\"text\" name=\"area\" size=\"16\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"area2zone\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" name=\"B1\" value=\"\\xb2\\xe9 \\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"/post/search.asp\" method=\"get\" name=\"zoneform\" target=\"searchwindow\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label>\\xc7\\xf8\\xba\\xc5\\xb2\\xe9\\xd1\\xaf\\xb5\\xd8\\xc3\\xfb</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input\" type=\"number\" name=\"zone\" size=\"10\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input type=\"hidden\" name=\"action\" value=\"zone2area\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" name=\"B1\" value=\"\\xb2\\xe9 \\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t</table>\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<strong><a href=\"http://www.ip138.com/post/postal22/\" target=\"_blank\">\\xd3\\xca\\xb1\\xe0\\xbc\\xb0\\xc7\\xf8\\xba\\xc5\\xcf\\xea\\xcf\\xb8\\xc1\\xd0\\xb1\\xed\\xca\\xbd\\xb2\\xe9\\xd1\\xaf</a></strong>\\r\\n\\t\\t\\t\\t\\t<strong><a href=\"http://www.ip138.com/post/yzbm/yzbm.htm\" target=\"_blank\">\\xd3\\xca\\xb1\\xe0\\xbc\\xb0\\xc7\\xf8\\xba\\xc5\\xb0\\xb4\\xb5\\xd8\\xcd\\xbc\\xb2\\xe9\\xd1\\xaf</a></strong>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-form\">\\r\\n\\t\\t\\t\\t<table width=\"80%\">\\r\\n\\t\\t\\t\\t\\t<caption>\\r\\n\\t\\t\\t\\t\\t\\t<a class=\"title\" href=\"http://qq.ip138.com/idsearch/\" target=\"_blank\">\\xb9\\xfa\\xc4\\xda\\xc9\\xed\\xb7\\xdd\\xd6\\xa4\\xba\\xc5\\xc2\\xeb\\xd1\\xe9\\xd6\\xa4\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t\\t(<a class=\"more\" href=\"http://qq.ip138.com/idsearch/\" target=\"_blank\">\\xb8\\xdf\\xbc\\xb6\\xb9\\xa6\\xc4\\xdc\\xb0\\xb4\\xb4\\xcb</a>)\\r\\n\\t\\t\\t\\t\\t</caption>\\r\\n\\t\\t\\t\\t\\t<tr>\\r\\n\\t\\t\\t\\t\\t\\t<td>\\r\\n\\t\\t\\t\\t\\t\\t\\t<form action=\"http://qq.ip138.com/idsearch/index.asp\" target=\"_blank\" method=\"get\" name=\"IDform\">\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<label>\\xc7\\xeb\\xca\\xe4\\xc8\\xeb15\\xbb\\xf218\\xce\\xbb\\xc9\\xed\\xb7\\xdd\\xd6\\xa4\\xba\\xc5</label>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"input large-input\" type=\"text\" name=\"userid\" value=\"\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input name=\"action\" type=\"hidden\" value=\"idcard\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t<input class=\"btn\" type=\"submit\" name=\"B1\" value=\"\\xb2\\xe9 \\xd1\\xaf\"/>\\r\\n\\t\\t\\t\\t\\t\\t\\t</form>\\r\\n\\t\\t\\t\\t\\t\\t</td>\\r\\n\\t\\t\\t\\t\\t</tr>\\r\\n\\t\\t\\t\\t</table>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-link\">\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<a href=\"/geshui/\" target=\"_blank\">\\xb8\\xf6\\xcb\\xb0\\xbc\\xc6\\xcb\\xe3\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/shijian/\" target=\"_blank\">\\xca\\xb1\\xbc\\xe4\\xbc\\xc6\\xcb\\xe3\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/chengwei/\" target=\"_blank\">\\xb3\\xc6\\xce\\xbd\\xbc\\xc6\\xcb\\xe3\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/shencai/\" target=\"_blank\">\\xc9\\xed\\xb8\\xdf\\xcc\\xe5\\xd6\\xd8\\xd7\\xd4\\xb2\\xe2</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/shengao/\" target=\"_blank\">\\xba\\xa2\\xd7\\xd3\\xc9\\xed\\xb8\\xdf\\xd4\\xa4\\xb2\\xe2</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/sanwei/\" target=\"_blank\">\\xc5\\xae\\xd0\\xd4\\xc8\\xfd\\xce\\xa7\\xd7\\xd4\\xb2\\xe2</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/anquanqi/\" target=\"_blank\">\\xb0\\xb2\\xc8\\xab\\xc6\\xda\\xbc\\xc6\\xcb\\xe3</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/yuchanqi/\" target=\"_blank\">\\xd4\\xa4\\xb2\\xfa\\xc6\\xda\\xbc\\xc6\\xcb\\xe3\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/chebiao/\" target=\"_blank\">\\xc6\\xfb\\xb3\\xb5\\xb1\\xea\\xd6\\xbe</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/biaozhi/\" target=\"_blank\">\\xbd\\xbb\\xcd\\xa8\\xb1\\xea\\xd6\\xbe</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/yuansu/\" target=\"_blank\">\\xd4\\xaa\\xcb\\xd8\\xd6\\xdc\\xc6\\xda\\xb1\\xed</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/jieri/\" target=\"_blank\">\\xbd\\xda\\xc8\\xd5\\xb4\\xf3\\xc8\\xab</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/huayu/\" target=\"_blank\">\\xbb\\xa8\\xd3\\xef\\xb4\\xf3\\xc8\\xab</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/xingzuo/\" target=\"_blank\">\\xca\\xae\\xb6\\xfe\\xd0\\xc7\\xd7\\xf9</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/jinji/\" target=\"_blank\">\\xca\\xc0\\xbd\\xe7\\xb8\\xf7\\xb9\\xfa\\xbd\\xfb\\xbc\\xc9</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/jiehun/\" target=\"_blank\">\\xbd\\xe1\\xbb\\xe9\\xbc\\xcd\\xc4\\xee\\xc8\\xd5</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/shoudu/\" target=\"_blank\">\\xb8\\xf7\\xb9\\xfa\\xca\\xd7\\xb6\\xbc</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/chaodai/\" target=\"_blank\">\\xc0\\xfa\\xca\\xb7\\xb3\\xaf\\xb4\\xfa</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/lingdai/\" target=\"_blank\">\\xc1\\xec\\xb4\\xf8\\xb4\\xf2\\xb7\\xa8</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/yuming/\" target=\"_blank\">\\xd3\\xf2\\xc3\\xfb\\xb7\\xd6\\xc0\\xe0</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/teshufuhao/\" target=\"_blank\">\\xcc\\xd8\\xca\\xe2\\xb7\\xfb\\xba\\xc5</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/24dian/\" target=\"_blank\">24\\xb5\\xe3\\xbc\\xc6\\xcb\\xe3\\xc6\\xf7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/mosi/\" target=\"_blank\">\\xc4\\xa6\\xcb\\xb9\\xc3\\xdc\\xc2\\xeb</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/minguo/\" target=\"_blank\">\\xc3\\xf1\\xb9\\xfa\\xc4\\xea\\xb7\\xdd\\xbb\\xbb\\xcb\\xe3</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/chima/\" target=\"_blank\">\\xb1\\xea\\xd7\\xbc\\xb3\\xdf\\xc2\\xeb\\xb6\\xd4\\xd5\\xd5\\xb1\\xed</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/rmb/\" target=\"_blank\">\\xc8\\xcb\\xc3\\xf1\\xb1\\xd2\\xb4\\xf3\\xd0\\xb4\\xd7\\xaa\\xbb\\xbb</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/utf8/\" target=\"_blank\">utf-8\\xb1\\xe0\\xc2\\xeb\\xd7\\xaa\\xbb\\xbb</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/ascii/\" target=\"_blank\">ascii\\xb1\\xe0\\xc2\\xeb\\xd7\\xaa\\xbb\\xbb</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/yanse/\" target=\"_blank\">\\xd4\\xda\\xcf\\xdf\\xb5\\xf7\\xc9\\xab\\xb0\\xe5</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/zhengze/\" target=\"_blank\">\\xd4\\xda\\xcf\\xdf\\xd5\\xfd\\xd4\\xf2\\xb2\\xe2\\xca\\xd4</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/zhuangtai/\" target=\"_blank\">http\\xd7\\xb4\\xcc\\xac\\xc2\\xeb\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/quchong/\" target=\"_blank\">\\xc8\\xa5\\xd6\\xd8\\xb9\\xa4\\xbe\\xdf</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/zishu/\" target=\"_blank\">\\xd7\\xd6\\xca\\xfd\\xcd\\xb3\\xbc\\xc6</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/miaobiao/\" target=\"_blank\">\\xd4\\xda\\xcf\\xdf\\xc3\\xeb\\xb1\\xed</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/useragent/\" target=\"_blank\">UA\\xb7\\xd6\\xce\\xf6</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/photoshop/\" target=\"_blank\">Photoshop\\xbf\\xec\\xbd\\xdd\\xbc\\xfc</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/jieqi/\" target=\"_blank\">\\xb6\\xfe\\xca\\xae\\xcb\\xc4\\xbd\\xda\\xc6\\xf8\\xb2\\xe9\\xd1\\xaf</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"/ditie/\" target=\"_blank\">\\xb3\\xc7\\xca\\xd0\\xb5\\xd8\\xcc\\xfa\\xcf\\xdf\\xc2\\xb7\\xcd\\xbc</a>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-friendlink\">\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://game.3533.com/game/\" target=\"_blank\">\\xca\\xd6\\xbb\\xfa\\xd3\\xce\\xcf\\xb7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.haolingsheng.com/\" target=\"_blank\">\\xca\\xd6\\xbb\\xfa\\xc1\\xe5\\xc9\\xf9</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.haobizhi.com/\" target=\"_blank\">\\xca\\xd6\\xbb\\xfa\\xb1\\xda\\xd6\\xbd</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://game.3533.com/ruanjian/\" target=\"_blank\">\\xca\\xd6\\xbb\\xfa\\xc8\\xed\\xbc\\xfe</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.4399.com/\" target=\"_blank\">4399\\xd0\\xa1\\xd3\\xce\\xcf\\xb7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://news.4399.com/wmpy/\" target=\"_blank\">\\xcd\\xea\\xc3\\xc0\\xc6\\xaf\\xd2\\xc6</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.oicq88.com/\" target=\"_blank\">QQ\\xcd\\xf8\\xc3\\xfb</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.fanxian.com/\" target=\"_blank\">\\xb7\\xb5\\xcf\\xd6\\xcd\\xf8</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.liantu.com/\" target=\"_blank\">\\xb6\\xfe\\xce\\xac\\xc2\\xeb</a>\\r\\n\\t\\t\\t\\t\\t<br/>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.4399dmw.com/donghua/\" target=\"_blank\">\\xb6\\xaf\\xbb\\xad\\xc6\\xac\\xb4\\xf3\\xc8\\xab</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.1zhe.com/\" target=\"_blank\">\\xd2\\xbb\\xd5\\xdb\\xcc\\xd8\\xc2\\xf4</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.4399.cn/\" target=\"_blank\">4399\\xca\\xd6\\xbb\\xfa\\xd3\\xce\\xcf\\xb7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"https://www.92987.com/360shoujizhushou.htm\" target=\"_blank\">360\\xca\\xd6\\xbb\\xfa\\xd6\\xfa\\xca\\xd6</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://app.4399.cn/\" target=\"_blank\">4399\\xd3\\xce\\xcf\\xb7\\xba\\xd0</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"https://www.92987.com/360shoujiweishi.htm\" target=\"_blank\">360\\xce\\xc0\\xca\\xbf</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.yy138.com/\" target=\"_blank\">\\xd3\\xa6\\xd3\\xc3\\xcf\\xc2\\xd4\\xd8</a>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t\\t<div class=\"module mod-foot\">\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t\\xcf\\xc3\\xc3\\xc5\\xca\\xd0\\xc2\\xfe\\xd3\\xce\\xbf\\xc6\\xbc\\xbc\\xd3\\xd0\\xcf\\xde\\xb9\\xab\\xcb\\xbe &nbsp; \\xb0\\xe6\\xc8\\xa8\\xcb\\xf9\\xd3\\xd0 &copy; 2017\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.miitbeian.gov.cn/\" rel=\"nofollow\" target=\"_blank\">\\xc3\\xf6ICP\\xb1\\xb815026659\\xba\\xc5-7</a>\\r\\n\\t\\t\\t\\t\\t<a href=\"http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35020302000956\" rel=\"nofollow\" target=\"_blank\"><img src=\"http://www.beian.gov.cn/img/ghs.png\" width=\"20\" height=\"20\" style=\"vertical-align:middle;\"> \\xc3\\xf6\\xb9\\xab\\xcd\\xf8\\xb0\\xb2\\xb1\\xb8 35020302000956\\xba\\xc5</a>\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t\\t<p>\\r\\n\\t\\t\\t\\t\\t\\xc1\\xaa\\xcf\\xb5\\xce\\xd2\\xc3\\xc7.\\xc7\\xeb<a href=\"mail.htm\" rel=\"nofollow\" target=\"_blank\">\\xb7\\xa2email</a>.\\xbb\\xf2\\xb8\\xf8<a href=\"http://qq.3533.com:8080/book.asp?siteid=7\" rel=\"nofollow\" target=\"_blank\">\\xce\\xd2\\xc3\\xc7\\xc1\\xf4\\xd1\\xd4</a>\\xd0\\xbb\\xd0\\xbb!\\r\\n\\t\\t\\t\\t</p>\\r\\n\\t\\t\\t</div>\\r\\n\\t\\t</div>\\r\\n\\t\\t<script type=\"text/javascript\">\\r\\n\\t\\t<!--\\r\\n\\t\\tif(!String.prototype.trim) {\\r\\n\\t\\t\\tString.prototype.trim = function () {\\r\\n\\t\\t\\t\\treturn this.replace(/^\\\\s+|\\\\s+$/g,\\'\\');\\r\\n\\t\\t\\t};\\r\\n\\t\\t}\\t\\t\\r\\n\\t\\t(function(){\\r\\n\\t\\t\\tvar reg = {\\r\\n\\t\\t\\t\\tmobile:/^1[3|4|5|6|7|8|9][0-9]{5,9}$/,\\r\\n\\t\\t\\t\\tzip:/^\\\\d{4,6}$/,\\r\\n\\t\\t\\t\\tzone:/^0\\\\d{2,6}$/,\\r\\n\\t\\t\\t\\tid:/^\\\\d{15}$|^\\\\d{18}$|^\\\\d{17}[xX]$/,\\r\\n\\t\\t\\t\\tdomain:/^([a-zA-Z0-9][-a-zA-Z0-9]{0,62}\\\\.)+([a-zA-Z]{2,63})\\\\.?$/\\r\\n\\t\\t\\t};\\r\\n\\t\\t\\tvar check = {\\r\\n\\t\\t\\t\\t\\'mobile\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.mobile.value.trim();\\r\\n\\t\\t\\t\\t\\tif(!value.length){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xb2\\xbb\\xc4\\xdc\\xce\\xaa\\xbf\\xd5\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.mobile.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}else if(!value.match(reg[\\'mobile\\'])){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xb2\\xbb\\xca\\xc7\\xcd\\xea\\xd5\\xfb\\xb5\\xc411\\xce\\xbb\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xbb\\xf2\\xd5\\xdf\\xd5\\xfd\\xc8\\xb7\\xb5\\xc4\\xca\\xd6\\xbb\\xfa\\xba\\xc5\\xc7\\xb0\\xc6\\xdf\\xce\\xbb\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.mobile.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t},\\r\\n\\t\\t\\t\\t\\'ip\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.ip.value.trim();\\r\\n\\t\\t\\t\\t\\tvalue = value.replace(/^http(s)?:\\\\/\\\\//,\\'\\').replace(/\\\\/$/,\\'\\');\\r\\n\\t\\t\\t\\t\\tif(!value.length){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xb5\\xd8\\xd6\\xb7\\xb2\\xbb\\xc4\\xdc\\xce\\xaa\\xbf\\xd5\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.ip.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}else if(value.match(/[A-Za-z_-]/)){\\r\\n\\t\\t\\t\\t\\t\\tif(!value.match(reg[\\'domain\\'])){\\r\\n\\t\\t\\t\\t\\t\\t\\talert(\\'\\xd3\\xf2\\xc3\\xfb\\xb8\\xf1\\xca\\xbd\\xb4\\xed\\xce\\xf3\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\t\\tthis.ip.focus();\\r\\n\\t\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t\\t}else{\\r\\n\\t\\t\\t\\t\\t\\tvar arr = value.split(\".\");\\r\\n\\t\\t\\t\\t\\t\\tif(arr.length!=4){\\r\\n\\t\\t\\t\\t\\t\\t\\talert(\"\\xb2\\xbb\\xca\\xc7\\xd5\\xfd\\xc8\\xb7\\xb5\\xc4IP\");\\r\\n\\t\\t\\t\\t\\t\\t\\tthis.ip.focus();\\r\\n\\t\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t\\t}else{\\r\\n\\t\\t\\t\\t\\t\\t\\tfor(var i=0;i<4;i++){\\r\\n\\t\\t\\t\\t\\t\\t\\t\\tif(isNaN(arr[i]) || arr[i].length<0 || arr[i]>255)\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t{\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\talert(\"\\xb2\\xbb\\xca\\xc7\\xd5\\xfd\\xc8\\xb7\\xb5\\xc4IP\");\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tthis.ip.focus();\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t\\tthis.ip.value = value;\\r\\n\\t\\t\\t\\t},\\r\\n\\t\\t\\t\\t\\'zip\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.zip.value.trim();\\r\\n\\t\\t\\t\\t\\tif(!value.match(reg[\\'zip\\'])){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xc7\\xeb\\xca\\xe4\\xc8\\xeb\\xd3\\xca\\xd5\\xfe\\xb1\\xe0\\xc2\\xeb\\xc7\\xb04-6\\xce\\xbb\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.zip.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t},\\r\\n\\t\\t\\t\\t\\'zone\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.zone.value.trim();\\r\\n\\t\\t\\t\\t\\tif(!value.match(reg[\\'zone\\'])){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xc7\\xeb\\xca\\xe4\\xc8\\xeb\\xd2\\xd4\\xa1\\xb00\\xa1\\xb1\\xbf\\xaa\\xcd\\xb7\\xb5\\xc43-7\\xce\\xbb\\xc7\\xf8\\xba\\xc5\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.zone.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t},\\r\\n\\t\\t\\t\\t\\'area\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.area.value.trim();\\r\\n\\t\\t\\t\\t\\tif(!value.length){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xc7\\xeb\\xca\\xe4\\xc8\\xeb\\xb5\\xd8\\xd6\\xb7\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.area.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}else if(value.length<2){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xb5\\xd8\\xd6\\xb7\\xd6\\xc1\\xc9\\xd9\\xd2\\xaa\\xd3\\xd02\\xb8\\xf6\\xd7\\xd6\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.area.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t},\\r\\n\\t\\t\\t\\t\\'id\\':function(){\\r\\n\\t\\t\\t\\t\\tvar value = this.userid.value.trim();\\r\\n\\t\\t\\t\\t\\tif(!value.match(reg[\\'id\\'])){\\r\\n\\t\\t\\t\\t\\t\\talert(\\'\\xc7\\xeb\\xca\\xe4\\xc8\\xeb15\\xce\\xbb\\xbb\\xf218\\xce\\xbb\\xc9\\xed\\xb7\\xdd\\xd6\\xa4\\xba\\xc5\\xa3\\xa1\\');\\r\\n\\t\\t\\t\\t\\t\\tthis.userid.focus();\\r\\n\\t\\t\\t\\t\\t\\treturn false;\\r\\n\\t\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\t}\\r\\n\\t\\t\\t};\\r\\n\\r\\n\\t\\t\\tdocument.ipform.onsubmit = check[\\'ip\\'];\\r\\n\\t\\t\\tdocument.area2zipForm.onsubmit = check[\\'area\\'];\\r\\n\\t\\t\\tdocument.zipform.onsubmit = check[\\'zip\\'];\\r\\n\\t\\t\\tdocument.area2zoneForm.onsubmit = check[\\'area\\'];\\r\\n\\t\\t\\tdocument.zoneform.onsubmit = check[\\'zone\\'];\\r\\n\\t\\t\\tdocument.getElementById(\\'luck\\').onclick = function (){\\r\\n\\t\\t\\t\\tvar value = document.mobileform.mobile.value.trim();\\r\\n\\t\\t\\t\\tif(value!=\\'\\'){\\r\\n\\t\\t\\t\\t\\tthis.href=\\'http://jx.ip138.com/search.asp?k=\\'+value;\\r\\n\\t\\t\\t\\t}\\r\\n\\t\\t\\t}\\r\\n\\t\\t\\tdocument.mobileform.onsubmit = check[\\'mobile\\'];\\r\\n\\t\\t\\tdocument.IDform.onsubmit = check[\\'id\\'];\\r\\n\\t\\t})();\\r\\n\\t\\t//-->\\r\\n\\t\\t</script>\\r\\n\\t\\t\\t<div style=\"display:none\">\\r\\n\\t\\t\\t\\t<script type=\"text/javascript\" src=\"http://tajs.qq.com/stats?sId=36241650\" charset=\"UTF-8\"></script>\\r\\n\\t\\t\\t</div>\\r\\n\\t</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    return urllib.request.urlopen(url).read()\n",
    "\n",
    "download('http://ip138.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n<meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\">\\n</html>\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    return urllib.request.urlopen(url).read()\n",
    "\n",
    "download('http://baidu.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-826aace44d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://ip138.com/1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-826aace44d14>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://ip138.com/1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    return urllib.request.urlopen(url).read()\n",
    "\n",
    "download('http://ip138.com/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://ip138.com/1\n",
      "Download error: Not Found\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "    return html\n",
    "\n",
    "\n",
    "download('http://ip138.com/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://www.williamlong.info/archives/aa.html\n",
      "Download error: Not Found\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "    return html\n",
    "\n",
    "\n",
    "download('http://www.williamlong.info/archives/aa.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/11.html\n",
      "Download error: Not Found\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "    return html\n",
    "\n",
    "\n",
    "download('https://webscraping.com/11.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "all(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "all(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, None]\n",
    "all(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import urllib.error\n",
    "\n",
    "\n",
    "print(issubclass(urllib.error.ContentTooShortError, urllib.error.URLError))\n",
    "print(issubclass(urllib.error.HTTPError, urllib.error.URLError))\n",
    "print(issubclass(urllib.error.URLError, OSError))\n",
    "print(issubclass(urllib.error.URLError, IOError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConnectionError,\n",
       " BlockingIOError,\n",
       " ChildProcessError,\n",
       " FileExistsError,\n",
       " FileNotFoundError,\n",
       " IsADirectoryError,\n",
       " NotADirectoryError,\n",
       " InterruptedError,\n",
       " PermissionError,\n",
       " ProcessLookupError,\n",
       " TimeoutError,\n",
       " io.UnsupportedOperation,\n",
       " signal.ItimerError,\n",
       " shutil.Error,\n",
       " shutil.SpecialFileError,\n",
       " shutil.ExecError,\n",
       " shutil.ReadError,\n",
       " socket.herror,\n",
       " socket.gaierror,\n",
       " socket.timeout,\n",
       " urllib.error.URLError]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OSError.__subclasses__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConnectionError,\n",
       " BlockingIOError,\n",
       " ChildProcessError,\n",
       " FileExistsError,\n",
       " FileNotFoundError,\n",
       " IsADirectoryError,\n",
       " NotADirectoryError,\n",
       " InterruptedError,\n",
       " PermissionError,\n",
       " ProcessLookupError,\n",
       " TimeoutError,\n",
       " io.UnsupportedOperation,\n",
       " signal.ItimerError,\n",
       " shutil.Error,\n",
       " shutil.SpecialFileError,\n",
       " shutil.ExecError,\n",
       " shutil.ReadError,\n",
       " socket.herror,\n",
       " socket.gaierror,\n",
       " socket.timeout,\n",
       " urllib.error.URLError]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IOError.__subclasses__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # recursively retry 5xx HTTP errors\n",
    "                return download(url, num_retries - 1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://httpstat.us/500\n",
      "Download error: Internal Server Error\n",
      "Downloading: http://httpstat.us/500\n",
      "Download error: Internal Server Error\n",
      "Downloading: http://httpstat.us/500\n",
      "Download error: Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # recursively retry 5xx HTTP errors\n",
    "                return download(url, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "download('http://httpstat.us/500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "php\n",
      "java\n",
      "<class 'dict_keys'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import Iterable\n",
    "\n",
    "\n",
    "d = {'python': 1, 'php': 2, 'java': 3}\n",
    "for key in d.keys():\n",
    "    print(key)\n",
    "print(type(d.keys()))\n",
    "print(isinstance(d.keys(), Iterable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 (default, Sep  4 2017, 20:58:07) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 (default, Sep  4 2017, 20:58:07) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "a = \"stackoverflow\"\n",
    "print(dir(a))\n",
    "print(hasattr(a, '__iter__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n",
      "http://webscraping.com\n",
      "http://webscraping.com/about\n",
      "http://webscraping.com/blog\n",
      "http://webscraping.com/blog/10/\n",
      "http://webscraping.com/blog/11/\n",
      "http://webscraping.com/blog/12/\n",
      "http://webscraping.com/blog/13/\n",
      "http://webscraping.com/blog/2/\n",
      "http://webscraping.com/blog/3/\n",
      "http://webscraping.com/blog/4/\n",
      "http://webscraping.com/blog/5/\n",
      "http://webscraping.com/blog/6/\n",
      "http://webscraping.com/blog/7/\n",
      "http://webscraping.com/blog/8/\n",
      "http://webscraping.com/blog/9/\n",
      "http://webscraping.com/blog/All-your-data-are-belong-to-us/\n",
      "http://webscraping.com/blog/Android-Apps-Update/\n",
      "http://webscraping.com/blog/Apple-Apps-Update/\n",
      "http://webscraping.com/blog/Asynchronous-support-in-Python/\n",
      "http://webscraping.com/blog/Automatic-web-scraping/\n",
      "http://webscraping.com/blog/Automating-CAPTCHAs/\n",
      "http://webscraping.com/blog/Automating-webkit/\n",
      "http://webscraping.com/blog/Best-website-for-freelancers/\n",
      "http://webscraping.com/blog/Bitcoin/\n",
      "http://webscraping.com/blog/Caching-crawled-webpages/\n",
      "http://webscraping.com/blog/Caching-data-efficiently/\n",
      "http://webscraping.com/blog/Can-you-extract-data-from-this-website/\n",
      "http://webscraping.com/blog/Client-Feedback/\n",
      "http://webscraping.com/blog/Converting-UK-Easting-Northing-coordinates/\n",
      "http://webscraping.com/blog/Crawling-with-threads/\n",
      "http://webscraping.com/blog/Discount-coupons-for-data-store/\n",
      "http://webscraping.com/blog/Extracting-article-summaries/\n",
      "http://webscraping.com/blog/Fixed-fee-or-hourly/\n",
      "http://webscraping.com/blog/Free-service-to-extract-article-from-webpage/\n",
      "http://webscraping.com/blog/Generate-website-screenshot-history/\n",
      "http://webscraping.com/blog/Google-App-Engine-limitations/\n",
      "http://webscraping.com/blog/Google-Storage/\n",
      "http://webscraping.com/blog/Google-interview/\n",
      "http://webscraping.com/blog/How-to-automatically-find-contact-details/\n",
      "http://webscraping.com/blog/How-to-crawl-websites-without-being-blocked/\n",
      "http://webscraping.com/blog/How-to-find-what-technology-a-website-uses/\n",
      "http://webscraping.com/blog/How-to-make-python-faster/\n",
      "http://webscraping.com/blog/How-to-protect-your-data/\n",
      "http://webscraping.com/blog/How-to-scrape-Android-Apps/\n",
      "http://webscraping.com/blog/How-to-teach-yourself-web-scraping/\n",
      "http://webscraping.com/blog/How-to-use-XPaths-robustly/\n",
      "http://webscraping.com/blog/How-to-use-proxies/\n",
      "http://webscraping.com/blog/I-love-AJAX/\n",
      "http://webscraping.com/blog/Image-efficiencies/\n",
      "http://webscraping.com/blog/Importing-CSV-into-MySQL/\n",
      "http://webscraping.com/blog/Increase-your-Google-App-Engine-quotas-for-free/\n",
      "http://webscraping.com/blog/Is-Web-Scraping-Legal/\n",
      "http://webscraping.com/blog/Loading-Cookies-from-the-Browser/\n",
      "http://webscraping.com/blog/Luminati/\n",
      "http://webscraping.com/blog/New-scraping-quote-tool/\n",
      "http://webscraping.com/blog/New-store-for-buying-databases/\n",
      "http://webscraping.com/blog/Open-sourced-web-scraping-code/\n",
      "http://webscraping.com/blog/Parsing-Flash-with-Swiffy/\n",
      "http://webscraping.com/blog/Parsing-HTML-with-Python/\n",
      "http://webscraping.com/blog/Rebranding-sitescraper-as-webscraping/\n",
      "http://webscraping.com/blog/Reverse-Geocode/\n",
      "http://webscraping.com/blog/Scraping-Flash-based-websites/\n",
      "http://webscraping.com/blog/Scraping-JavaScript-based-web-pages-with-Chickenfoot/\n",
      "http://webscraping.com/blog/Scraping-JavaScript-webpages-with-webkit/\n",
      "http://webscraping.com/blog/Scraping-dynamic-data/\n",
      "http://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/\n",
      "http://webscraping.com/blog/Services/\n",
      "http://webscraping.com/blog/Solving-CAPTCHA/\n",
      "http://webscraping.com/blog/Startup/\n",
      "http://webscraping.com/blog/Taking-advantage-of-mobile-interfaces/\n",
      "http://webscraping.com/blog/The-SiteScraper-module/\n",
      "http://webscraping.com/blog/Threading-with-webkit/\n",
      "http://webscraping.com/blog/Typical-web-scraping-job/\n",
      "http://webscraping.com/blog/UPC-Database-Update/\n",
      "http://webscraping.com/blog/Useful-business-directories/\n",
      "http://webscraping.com/blog/User-agents/\n",
      "http://webscraping.com/blog/Using-Google-Cache-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Using-Google-Translate-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Using-the-internet-archive-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Web-Scraping-Interface/\n",
      "http://webscraping.com/blog/Web-Scrapping/\n",
      "http://webscraping.com/blog/Web-scraping-with-regular-expressions/\n",
      "http://webscraping.com/blog/Webpage-screenshots-with-webkit/\n",
      "http://webscraping.com/blog/What-is-CSV/\n",
      "http://webscraping.com/blog/What-is-web-scraping/\n",
      "http://webscraping.com/blog/Why-Google-App-Engine/\n",
      "http://webscraping.com/blog/Why-Python/\n",
      "http://webscraping.com/blog/Why-reinvent-the-wheel/\n",
      "http://webscraping.com/blog/Why-web2py/\n",
      "http://webscraping.com/blog/category/ajax\n",
      "http://webscraping.com/blog/category/android/\n",
      "http://webscraping.com/blog/category/beautifulsoup\n",
      "http://webscraping.com/blog/category/big picture\n",
      "http://webscraping.com/blog/category/business/\n",
      "http://webscraping.com/blog/category/cache\n",
      "http://webscraping.com/blog/category/captcha\n",
      "http://webscraping.com/blog/category/chickenfoot\n",
      "http://webscraping.com/blog/category/concurrent\n",
      "http://webscraping.com/blog/category/cookies\n",
      "http://webscraping.com/blog/category/crawling\n",
      "http://webscraping.com/blog/category/database/\n",
      "http://webscraping.com/blog/category/efficiency\n",
      "http://webscraping.com/blog/category/elance\n",
      "http://webscraping.com/blog/category/example\n",
      "http://webscraping.com/blog/category/flash\n",
      "http://webscraping.com/blog/category/freelancing\n",
      "http://webscraping.com/blog/category/gae\n",
      "http://webscraping.com/blog/category/google/\n",
      "http://webscraping.com/blog/category/html\n",
      "http://webscraping.com/blog/category/image\n",
      "http://webscraping.com/blog/category/ip\n",
      "http://webscraping.com/blog/category/ir\n",
      "http://webscraping.com/blog/category/javascript\n",
      "http://webscraping.com/blog/category/learn\n",
      "http://webscraping.com/blog/category/linux\n",
      "http://webscraping.com/blog/category/lxml\n",
      "http://webscraping.com/blog/category/mobile\n",
      "http://webscraping.com/blog/category/mobile apps/\n",
      "http://webscraping.com/blog/category/ocr\n",
      "http://webscraping.com/blog/category/opensource\n",
      "http://webscraping.com/blog/category/proxies/\n",
      "http://webscraping.com/blog/category/python\n",
      "http://webscraping.com/blog/category/qt\n",
      "http://webscraping.com/blog/category/regex\n",
      "http://webscraping.com/blog/category/scrapy\n",
      "http://webscraping.com/blog/category/screenshot\n",
      "http://webscraping.com/blog/category/sitescraper\n",
      "http://webscraping.com/blog/category/sqlite\n",
      "http://webscraping.com/blog/category/user-agent\n",
      "http://webscraping.com/blog/category/web2py\n",
      "http://webscraping.com/blog/category/webkit\n",
      "http://webscraping.com/blog/category/website/\n",
      "http://webscraping.com/blog/category/xpath\n",
      "http://webscraping.com/contact\n",
      "http://webscraping.com/data\n",
      "http://webscraping.com/data/default/database/1/belgium-zip-codes\n",
      "http://webscraping.com/data/default/database/10/usa-restaurants\n",
      "http://webscraping.com/data/default/database/11/android-apps\n",
      "http://webscraping.com/data/default/database/12/universal-product-codes-upc-details\n",
      "http://webscraping.com/data/default/database/13/international-standard-book-numbers-isbn\n",
      "http://webscraping.com/data/default/database/14/hotel-details\n",
      "http://webscraping.com/data/default/database/17/aircraft-models\n",
      "http://webscraping.com/data/default/database/2/usa-cities\n",
      "http://webscraping.com/data/default/database/23/films\n",
      "http://webscraping.com/data/default/database/29/popular-websites\n",
      "http://webscraping.com/data/default/database/3/world-cities\n",
      "http://webscraping.com/data/default/database/31/german-businesses\n",
      "http://webscraping.com/data/default/database/33/australian-businesses\n",
      "http://webscraping.com/data/default/database/37/united-kingdom-postcodes\n",
      "http://webscraping.com/data/default/database/4/united-kingdom-cities\n",
      "http://webscraping.com/data/default/database/41/world-zip-codes\n",
      "http://webscraping.com/data/default/database/5/famous-quotes\n",
      "http://webscraping.com/data/default/database/52/universal-product-codes-upc-list\n",
      "http://webscraping.com/data/default/database/53/summer-olympic-medals\n",
      "http://webscraping.com/data/default/database/54/winter-olympic-medal-count\n",
      "http://webscraping.com/data/default/database/55/song-lyrics\n",
      "http://webscraping.com/data/default/database/57/amazon-standard-identification-numbers-asin-details\n",
      "http://webscraping.com/data/default/database/58/salaries\n",
      "http://webscraping.com/data/default/database/59/usa-people\n",
      "http://webscraping.com/data/default/database/6/canada-cities\n",
      "http://webscraping.com/data/default/database/60/blackberry-apps\n",
      "http://webscraping.com/data/default/database/62/windows-phone-apps\n",
      "http://webscraping.com/data/default/database/64/recipes\n",
      "http://webscraping.com/data/default/database/65/australian-real-estate-agents\n",
      "http://webscraping.com/data/default/database/66/european-businesses\n",
      "http://webscraping.com/data/default/database/68/uk-businesses\n",
      "http://webscraping.com/data/default/database/69/new-zealand-real-estate-agents\n",
      "http://webscraping.com/data/default/database/7/apple-ios-apps\n",
      "http://webscraping.com/data/default/database/70/usa-businesses\n",
      "http://webscraping.com/data/default/database/71/usa-real-estate-agents\n",
      "http://webscraping.com/data/default/database/8/amazon-standard-identification-numbers-asin\n",
      "http://webscraping.com/data/default/database/9/world-restaurants\n",
      "http://webscraping.com/data/default/index?page=0\n",
      "http://webscraping.com/data/default/index?page=1\n",
      "http://webscraping.com/data/default/index?page=2\n",
      "http://webscraping.com/data/default/index?page=3\n",
      "http://webscraping.com/data/default/index?page=4\n",
      "http://webscraping.com/data/default/index?page=5\n",
      "http://webscraping.com/data/default/index?page=6\n",
      "http://webscraping.com/feedback\n",
      "http://webscraping.com/quote\n",
      "http://webscraping.com/shame\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "links = re.findall('<loc>(.*?)</loc>', download('https://webscraping.com/sitemap.xml').decode())\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n",
      "http://webscraping.com\n",
      "http://webscraping.com/about\n",
      "http://webscraping.com/blog\n",
      "http://webscraping.com/blog/10/\n",
      "http://webscraping.com/blog/11/\n",
      "http://webscraping.com/blog/12/\n",
      "http://webscraping.com/blog/13/\n",
      "http://webscraping.com/blog/2/\n",
      "http://webscraping.com/blog/3/\n",
      "http://webscraping.com/blog/4/\n",
      "http://webscraping.com/blog/5/\n",
      "http://webscraping.com/blog/6/\n",
      "http://webscraping.com/blog/7/\n",
      "http://webscraping.com/blog/8/\n",
      "http://webscraping.com/blog/9/\n",
      "http://webscraping.com/blog/All-your-data-are-belong-to-us/\n",
      "http://webscraping.com/blog/Android-Apps-Update/\n",
      "http://webscraping.com/blog/Apple-Apps-Update/\n",
      "http://webscraping.com/blog/Asynchronous-support-in-Python/\n",
      "http://webscraping.com/blog/Automatic-web-scraping/\n",
      "http://webscraping.com/blog/Automating-CAPTCHAs/\n",
      "http://webscraping.com/blog/Automating-webkit/\n",
      "http://webscraping.com/blog/Best-website-for-freelancers/\n",
      "http://webscraping.com/blog/Bitcoin/\n",
      "http://webscraping.com/blog/Caching-crawled-webpages/\n",
      "http://webscraping.com/blog/Caching-data-efficiently/\n",
      "http://webscraping.com/blog/Can-you-extract-data-from-this-website/\n",
      "http://webscraping.com/blog/Client-Feedback/\n",
      "http://webscraping.com/blog/Converting-UK-Easting-Northing-coordinates/\n",
      "http://webscraping.com/blog/Crawling-with-threads/\n",
      "http://webscraping.com/blog/Discount-coupons-for-data-store/\n",
      "http://webscraping.com/blog/Extracting-article-summaries/\n",
      "http://webscraping.com/blog/Fixed-fee-or-hourly/\n",
      "http://webscraping.com/blog/Free-service-to-extract-article-from-webpage/\n",
      "http://webscraping.com/blog/Generate-website-screenshot-history/\n",
      "http://webscraping.com/blog/Google-App-Engine-limitations/\n",
      "http://webscraping.com/blog/Google-Storage/\n",
      "http://webscraping.com/blog/Google-interview/\n",
      "http://webscraping.com/blog/How-to-automatically-find-contact-details/\n",
      "http://webscraping.com/blog/How-to-crawl-websites-without-being-blocked/\n",
      "http://webscraping.com/blog/How-to-find-what-technology-a-website-uses/\n",
      "http://webscraping.com/blog/How-to-make-python-faster/\n",
      "http://webscraping.com/blog/How-to-protect-your-data/\n",
      "http://webscraping.com/blog/How-to-scrape-Android-Apps/\n",
      "http://webscraping.com/blog/How-to-teach-yourself-web-scraping/\n",
      "http://webscraping.com/blog/How-to-use-XPaths-robustly/\n",
      "http://webscraping.com/blog/How-to-use-proxies/\n",
      "http://webscraping.com/blog/I-love-AJAX/\n",
      "http://webscraping.com/blog/Image-efficiencies/\n",
      "http://webscraping.com/blog/Importing-CSV-into-MySQL/\n",
      "http://webscraping.com/blog/Increase-your-Google-App-Engine-quotas-for-free/\n",
      "http://webscraping.com/blog/Is-Web-Scraping-Legal/\n",
      "http://webscraping.com/blog/Loading-Cookies-from-the-Browser/\n",
      "http://webscraping.com/blog/Luminati/\n",
      "http://webscraping.com/blog/New-scraping-quote-tool/\n",
      "http://webscraping.com/blog/New-store-for-buying-databases/\n",
      "http://webscraping.com/blog/Open-sourced-web-scraping-code/\n",
      "http://webscraping.com/blog/Parsing-Flash-with-Swiffy/\n",
      "http://webscraping.com/blog/Parsing-HTML-with-Python/\n",
      "http://webscraping.com/blog/Rebranding-sitescraper-as-webscraping/\n",
      "http://webscraping.com/blog/Reverse-Geocode/\n",
      "http://webscraping.com/blog/Scraping-Flash-based-websites/\n",
      "http://webscraping.com/blog/Scraping-JavaScript-based-web-pages-with-Chickenfoot/\n",
      "http://webscraping.com/blog/Scraping-JavaScript-webpages-with-webkit/\n",
      "http://webscraping.com/blog/Scraping-dynamic-data/\n",
      "http://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/\n",
      "http://webscraping.com/blog/Services/\n",
      "http://webscraping.com/blog/Solving-CAPTCHA/\n",
      "http://webscraping.com/blog/Startup/\n",
      "http://webscraping.com/blog/Taking-advantage-of-mobile-interfaces/\n",
      "http://webscraping.com/blog/The-SiteScraper-module/\n",
      "http://webscraping.com/blog/Threading-with-webkit/\n",
      "http://webscraping.com/blog/Typical-web-scraping-job/\n",
      "http://webscraping.com/blog/UPC-Database-Update/\n",
      "http://webscraping.com/blog/Useful-business-directories/\n",
      "http://webscraping.com/blog/User-agents/\n",
      "http://webscraping.com/blog/Using-Google-Cache-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Using-Google-Translate-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Using-the-internet-archive-to-crawl-a-website/\n",
      "http://webscraping.com/blog/Web-Scraping-Interface/\n",
      "http://webscraping.com/blog/Web-Scrapping/\n",
      "http://webscraping.com/blog/Web-scraping-with-regular-expressions/\n",
      "http://webscraping.com/blog/Webpage-screenshots-with-webkit/\n",
      "http://webscraping.com/blog/What-is-CSV/\n",
      "http://webscraping.com/blog/What-is-web-scraping/\n",
      "http://webscraping.com/blog/Why-Google-App-Engine/\n",
      "http://webscraping.com/blog/Why-Python/\n",
      "http://webscraping.com/blog/Why-reinvent-the-wheel/\n",
      "http://webscraping.com/blog/Why-web2py/\n",
      "http://webscraping.com/blog/category/ajax\n",
      "http://webscraping.com/blog/category/android/\n",
      "http://webscraping.com/blog/category/beautifulsoup\n",
      "http://webscraping.com/blog/category/big picture\n",
      "http://webscraping.com/blog/category/business/\n",
      "http://webscraping.com/blog/category/cache\n",
      "http://webscraping.com/blog/category/captcha\n",
      "http://webscraping.com/blog/category/chickenfoot\n",
      "http://webscraping.com/blog/category/concurrent\n",
      "http://webscraping.com/blog/category/cookies\n",
      "http://webscraping.com/blog/category/crawling\n",
      "http://webscraping.com/blog/category/database/\n",
      "http://webscraping.com/blog/category/efficiency\n",
      "http://webscraping.com/blog/category/elance\n",
      "http://webscraping.com/blog/category/example\n",
      "http://webscraping.com/blog/category/flash\n",
      "http://webscraping.com/blog/category/freelancing\n",
      "http://webscraping.com/blog/category/gae\n",
      "http://webscraping.com/blog/category/google/\n",
      "http://webscraping.com/blog/category/html\n",
      "http://webscraping.com/blog/category/image\n",
      "http://webscraping.com/blog/category/ip\n",
      "http://webscraping.com/blog/category/ir\n",
      "http://webscraping.com/blog/category/javascript\n",
      "http://webscraping.com/blog/category/learn\n",
      "http://webscraping.com/blog/category/linux\n",
      "http://webscraping.com/blog/category/lxml\n",
      "http://webscraping.com/blog/category/mobile\n",
      "http://webscraping.com/blog/category/mobile apps/\n",
      "http://webscraping.com/blog/category/ocr\n",
      "http://webscraping.com/blog/category/opensource\n",
      "http://webscraping.com/blog/category/proxies/\n",
      "http://webscraping.com/blog/category/python\n",
      "http://webscraping.com/blog/category/qt\n",
      "http://webscraping.com/blog/category/regex\n",
      "http://webscraping.com/blog/category/scrapy\n",
      "http://webscraping.com/blog/category/screenshot\n",
      "http://webscraping.com/blog/category/sitescraper\n",
      "http://webscraping.com/blog/category/sqlite\n",
      "http://webscraping.com/blog/category/user-agent\n",
      "http://webscraping.com/blog/category/web2py\n",
      "http://webscraping.com/blog/category/webkit\n",
      "http://webscraping.com/blog/category/website/\n",
      "http://webscraping.com/blog/category/xpath\n",
      "http://webscraping.com/contact\n",
      "http://webscraping.com/data\n",
      "http://webscraping.com/data/default/database/1/belgium-zip-codes\n",
      "http://webscraping.com/data/default/database/10/usa-restaurants\n",
      "http://webscraping.com/data/default/database/11/android-apps\n",
      "http://webscraping.com/data/default/database/12/universal-product-codes-upc-details\n",
      "http://webscraping.com/data/default/database/13/international-standard-book-numbers-isbn\n",
      "http://webscraping.com/data/default/database/14/hotel-details\n",
      "http://webscraping.com/data/default/database/17/aircraft-models\n",
      "http://webscraping.com/data/default/database/2/usa-cities\n",
      "http://webscraping.com/data/default/database/23/films\n",
      "http://webscraping.com/data/default/database/29/popular-websites\n",
      "http://webscraping.com/data/default/database/3/world-cities\n",
      "http://webscraping.com/data/default/database/31/german-businesses\n",
      "http://webscraping.com/data/default/database/33/australian-businesses\n",
      "http://webscraping.com/data/default/database/37/united-kingdom-postcodes\n",
      "http://webscraping.com/data/default/database/4/united-kingdom-cities\n",
      "http://webscraping.com/data/default/database/41/world-zip-codes\n",
      "http://webscraping.com/data/default/database/5/famous-quotes\n",
      "http://webscraping.com/data/default/database/52/universal-product-codes-upc-list\n",
      "http://webscraping.com/data/default/database/53/summer-olympic-medals\n",
      "http://webscraping.com/data/default/database/54/winter-olympic-medal-count\n",
      "http://webscraping.com/data/default/database/55/song-lyrics\n",
      "http://webscraping.com/data/default/database/57/amazon-standard-identification-numbers-asin-details\n",
      "http://webscraping.com/data/default/database/58/salaries\n",
      "http://webscraping.com/data/default/database/59/usa-people\n",
      "http://webscraping.com/data/default/database/6/canada-cities\n",
      "http://webscraping.com/data/default/database/60/blackberry-apps\n",
      "http://webscraping.com/data/default/database/62/windows-phone-apps\n",
      "http://webscraping.com/data/default/database/64/recipes\n",
      "http://webscraping.com/data/default/database/65/australian-real-estate-agents\n",
      "http://webscraping.com/data/default/database/66/european-businesses\n",
      "http://webscraping.com/data/default/database/68/uk-businesses\n",
      "http://webscraping.com/data/default/database/69/new-zealand-real-estate-agents\n",
      "http://webscraping.com/data/default/database/7/apple-ios-apps\n",
      "http://webscraping.com/data/default/database/70/usa-businesses\n",
      "http://webscraping.com/data/default/database/71/usa-real-estate-agents\n",
      "http://webscraping.com/data/default/database/8/amazon-standard-identification-numbers-asin\n",
      "http://webscraping.com/data/default/database/9/world-restaurants\n",
      "http://webscraping.com/data/default/index?page=0\n",
      "http://webscraping.com/data/default/index?page=1\n",
      "http://webscraping.com/data/default/index?page=2\n",
      "http://webscraping.com/data/default/index?page=3\n",
      "http://webscraping.com/data/default/index?page=4\n",
      "http://webscraping.com/data/default/index?page=5\n",
      "http://webscraping.com/data/default/index?page=6\n",
      "http://webscraping.com/feedback\n",
      "http://webscraping.com/quote\n",
      "http://webscraping.com/shame\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "links = re.findall('<loc>(.*)</loc>', download('https://webscraping.com/sitemap.xml').decode())\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n",
      "<class 'bytes'>\n",
      "Downloading: https://webscraping.com/sitemap.xml\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "print(type(download('https://webscraping.com/sitemap.xml')))\n",
    "print(type(download('https://webscraping.com/sitemap.xml').decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\\n<url><loc>http://webscraping.com</loc></url>\\n<url><loc>http://webscraping.com/about</loc></url>\\n<url><loc>http://webscraping.com/blog</loc></url>\\n<url><loc>http://webscraping.com/blog/10/</loc></url>\\n<url><loc>http://webscraping.com/blog/11/</loc></url>\\n<url><loc>http://webscraping.com/blog/12/</loc></url>\\n<url><loc>http://webscraping.com/blog/13/</loc></url>\\n<url><loc>http://webscraping.com/blog/2/</loc></url>\\n<url><loc>http://webscraping.com/blog/3/</loc></url>\\n<url><loc>http://webscraping.com/blog/4/</loc></url>\\n<url><loc>http://webscraping.com/blog/5/</loc></url>\\n<url><loc>http://webscraping.com/blog/6/</loc></url>\\n<url><loc>http://webscraping.com/blog/7/</loc></url>\\n<url><loc>http://webscraping.com/blog/8/</loc></url>\\n<url><loc>http://webscraping.com/blog/9/</loc></url>\\n<url><loc>http://webscraping.com/blog/All-your-data-are-belong-to-us/</loc></url>\\n<url><loc>http://webscraping.com/blog/Android-Apps-Update/</loc></url>\\n<url><loc>http://webscraping.com/blog/Apple-Apps-Update/</loc></url>\\n<url><loc>http://webscraping.com/blog/Asynchronous-support-in-Python/</loc></url>\\n<url><loc>http://webscraping.com/blog/Automatic-web-scraping/</loc></url>\\n<url><loc>http://webscraping.com/blog/Automating-CAPTCHAs/</loc></url>\\n<url><loc>http://webscraping.com/blog/Automating-webkit/</loc></url>\\n<url><loc>http://webscraping.com/blog/Best-website-for-freelancers/</loc></url>\\n<url><loc>http://webscraping.com/blog/Bitcoin/</loc></url>\\n<url><loc>http://webscraping.com/blog/Caching-crawled-webpages/</loc></url>\\n<url><loc>http://webscraping.com/blog/Caching-data-efficiently/</loc></url>\\n<url><loc>http://webscraping.com/blog/Can-you-extract-data-from-this-website/</loc></url>\\n<url><loc>http://webscraping.com/blog/Client-Feedback/</loc></url>\\n<url><loc>http://webscraping.com/blog/Converting-UK-Easting-Northing-coordinates/</loc></url>\\n<url><loc>http://webscraping.com/blog/Crawling-with-threads/</loc></url>\\n<url><loc>http://webscraping.com/blog/Discount-coupons-for-data-store/</loc></url>\\n<url><loc>http://webscraping.com/blog/Extracting-article-summaries/</loc></url>\\n<url><loc>http://webscraping.com/blog/Fixed-fee-or-hourly/</loc></url>\\n<url><loc>http://webscraping.com/blog/Free-service-to-extract-article-from-webpage/</loc></url>\\n<url><loc>http://webscraping.com/blog/Generate-website-screenshot-history/</loc></url>\\n<url><loc>http://webscraping.com/blog/Google-App-Engine-limitations/</loc></url>\\n<url><loc>http://webscraping.com/blog/Google-Storage/</loc></url>\\n<url><loc>http://webscraping.com/blog/Google-interview/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-automatically-find-contact-details/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-crawl-websites-without-being-blocked/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-find-what-technology-a-website-uses/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-make-python-faster/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-protect-your-data/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-scrape-Android-Apps/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-teach-yourself-web-scraping/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-use-XPaths-robustly/</loc></url>\\n<url><loc>http://webscraping.com/blog/How-to-use-proxies/</loc></url>\\n<url><loc>http://webscraping.com/blog/I-love-AJAX/</loc></url>\\n<url><loc>http://webscraping.com/blog/Image-efficiencies/</loc></url>\\n<url><loc>http://webscraping.com/blog/Importing-CSV-into-MySQL/</loc></url>\\n<url><loc>http://webscraping.com/blog/Increase-your-Google-App-Engine-quotas-for-free/</loc></url>\\n<url><loc>http://webscraping.com/blog/Is-Web-Scraping-Legal/</loc></url>\\n<url><loc>http://webscraping.com/blog/Loading-Cookies-from-the-Browser/</loc></url>\\n<url><loc>http://webscraping.com/blog/Luminati/</loc></url>\\n<url><loc>http://webscraping.com/blog/New-scraping-quote-tool/</loc></url>\\n<url><loc>http://webscraping.com/blog/New-store-for-buying-databases/</loc></url>\\n<url><loc>http://webscraping.com/blog/Open-sourced-web-scraping-code/</loc></url>\\n<url><loc>http://webscraping.com/blog/Parsing-Flash-with-Swiffy/</loc></url>\\n<url><loc>http://webscraping.com/blog/Parsing-HTML-with-Python/</loc></url>\\n<url><loc>http://webscraping.com/blog/Rebranding-sitescraper-as-webscraping/</loc></url>\\n<url><loc>http://webscraping.com/blog/Reverse-Geocode/</loc></url>\\n<url><loc>http://webscraping.com/blog/Scraping-Flash-based-websites/</loc></url>\\n<url><loc>http://webscraping.com/blog/Scraping-JavaScript-based-web-pages-with-Chickenfoot/</loc></url>\\n<url><loc>http://webscraping.com/blog/Scraping-JavaScript-webpages-with-webkit/</loc></url>\\n<url><loc>http://webscraping.com/blog/Scraping-dynamic-data/</loc></url>\\n<url><loc>http://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/</loc></url>\\n<url><loc>http://webscraping.com/blog/Services/</loc></url>\\n<url><loc>http://webscraping.com/blog/Solving-CAPTCHA/</loc></url>\\n<url><loc>http://webscraping.com/blog/Startup/</loc></url>\\n<url><loc>http://webscraping.com/blog/Taking-advantage-of-mobile-interfaces/</loc></url>\\n<url><loc>http://webscraping.com/blog/The-SiteScraper-module/</loc></url>\\n<url><loc>http://webscraping.com/blog/Threading-with-webkit/</loc></url>\\n<url><loc>http://webscraping.com/blog/Typical-web-scraping-job/</loc></url>\\n<url><loc>http://webscraping.com/blog/UPC-Database-Update/</loc></url>\\n<url><loc>http://webscraping.com/blog/Useful-business-directories/</loc></url>\\n<url><loc>http://webscraping.com/blog/User-agents/</loc></url>\\n<url><loc>http://webscraping.com/blog/Using-Google-Cache-to-crawl-a-website/</loc></url>\\n<url><loc>http://webscraping.com/blog/Using-Google-Translate-to-crawl-a-website/</loc></url>\\n<url><loc>http://webscraping.com/blog/Using-the-internet-archive-to-crawl-a-website/</loc></url>\\n<url><loc>http://webscraping.com/blog/Web-Scraping-Interface/</loc></url>\\n<url><loc>http://webscraping.com/blog/Web-Scrapping/</loc></url>\\n<url><loc>http://webscraping.com/blog/Web-scraping-with-regular-expressions/</loc></url>\\n<url><loc>http://webscraping.com/blog/Webpage-screenshots-with-webkit/</loc></url>\\n<url><loc>http://webscraping.com/blog/What-is-CSV/</loc></url>\\n<url><loc>http://webscraping.com/blog/What-is-web-scraping/</loc></url>\\n<url><loc>http://webscraping.com/blog/Why-Google-App-Engine/</loc></url>\\n<url><loc>http://webscraping.com/blog/Why-Python/</loc></url>\\n<url><loc>http://webscraping.com/blog/Why-reinvent-the-wheel/</loc></url>\\n<url><loc>http://webscraping.com/blog/Why-web2py/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/ajax</loc></url>\\n<url><loc>http://webscraping.com/blog/category/android/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/beautifulsoup</loc></url>\\n<url><loc>http://webscraping.com/blog/category/big picture</loc></url>\\n<url><loc>http://webscraping.com/blog/category/business/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/cache</loc></url>\\n<url><loc>http://webscraping.com/blog/category/captcha</loc></url>\\n<url><loc>http://webscraping.com/blog/category/chickenfoot</loc></url>\\n<url><loc>http://webscraping.com/blog/category/concurrent</loc></url>\\n<url><loc>http://webscraping.com/blog/category/cookies</loc></url>\\n<url><loc>http://webscraping.com/blog/category/crawling</loc></url>\\n<url><loc>http://webscraping.com/blog/category/database/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/efficiency</loc></url>\\n<url><loc>http://webscraping.com/blog/category/elance</loc></url>\\n<url><loc>http://webscraping.com/blog/category/example</loc></url>\\n<url><loc>http://webscraping.com/blog/category/flash</loc></url>\\n<url><loc>http://webscraping.com/blog/category/freelancing</loc></url>\\n<url><loc>http://webscraping.com/blog/category/gae</loc></url>\\n<url><loc>http://webscraping.com/blog/category/google/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/html</loc></url>\\n<url><loc>http://webscraping.com/blog/category/image</loc></url>\\n<url><loc>http://webscraping.com/blog/category/ip</loc></url>\\n<url><loc>http://webscraping.com/blog/category/ir</loc></url>\\n<url><loc>http://webscraping.com/blog/category/javascript</loc></url>\\n<url><loc>http://webscraping.com/blog/category/learn</loc></url>\\n<url><loc>http://webscraping.com/blog/category/linux</loc></url>\\n<url><loc>http://webscraping.com/blog/category/lxml</loc></url>\\n<url><loc>http://webscraping.com/blog/category/mobile</loc></url>\\n<url><loc>http://webscraping.com/blog/category/mobile apps/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/ocr</loc></url>\\n<url><loc>http://webscraping.com/blog/category/opensource</loc></url>\\n<url><loc>http://webscraping.com/blog/category/proxies/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/python</loc></url>\\n<url><loc>http://webscraping.com/blog/category/qt</loc></url>\\n<url><loc>http://webscraping.com/blog/category/regex</loc></url>\\n<url><loc>http://webscraping.com/blog/category/scrapy</loc></url>\\n<url><loc>http://webscraping.com/blog/category/screenshot</loc></url>\\n<url><loc>http://webscraping.com/blog/category/sitescraper</loc></url>\\n<url><loc>http://webscraping.com/blog/category/sqlite</loc></url>\\n<url><loc>http://webscraping.com/blog/category/user-agent</loc></url>\\n<url><loc>http://webscraping.com/blog/category/web2py</loc></url>\\n<url><loc>http://webscraping.com/blog/category/webkit</loc></url>\\n<url><loc>http://webscraping.com/blog/category/website/</loc></url>\\n<url><loc>http://webscraping.com/blog/category/xpath</loc></url>\\n<url><loc>http://webscraping.com/contact</loc></url>\\n<url><loc>http://webscraping.com/data</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/1/belgium-zip-codes</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/10/usa-restaurants</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/11/android-apps</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/12/universal-product-codes-upc-details</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/13/international-standard-book-numbers-isbn</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/14/hotel-details</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/17/aircraft-models</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/2/usa-cities</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/23/films</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/29/popular-websites</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/3/world-cities</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/31/german-businesses</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/33/australian-businesses</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/37/united-kingdom-postcodes</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/4/united-kingdom-cities</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/41/world-zip-codes</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/5/famous-quotes</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/52/universal-product-codes-upc-list</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/53/summer-olympic-medals</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/54/winter-olympic-medal-count</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/55/song-lyrics</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/57/amazon-standard-identification-numbers-asin-details</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/58/salaries</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/59/usa-people</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/6/canada-cities</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/60/blackberry-apps</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/62/windows-phone-apps</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/64/recipes</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/65/australian-real-estate-agents</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/66/european-businesses</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/68/uk-businesses</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/69/new-zealand-real-estate-agents</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/7/apple-ios-apps</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/70/usa-businesses</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/71/usa-real-estate-agents</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/8/amazon-standard-identification-numbers-asin</loc></url>\\n<url><loc>http://webscraping.com/data/default/database/9/world-restaurants</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=0</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=1</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=2</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=3</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=4</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=5</loc></url>\\n<url><loc>http://webscraping.com/data/default/index?page=6</loc></url>\\n<url><loc>http://webscraping.com/feedback</loc></url>\\n<url><loc>http://webscraping.com/quote</loc></url>\\n<url><loc>http://webscraping.com/shame</loc></url>\\n</urlset>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "download('https://webscraping.com/sitemap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).status\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "download('https://webscraping.com/sitemap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).version\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "download('https://webscraping.com/sitemap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://webscraping.com/sitemap.xml\n",
      "['http://webscraping.com', 'http://webscraping.com/about', 'http://webscraping.com/blog', 'http://webscraping.com/blog/10/', 'http://webscraping.com/blog/11/', 'http://webscraping.com/blog/12/', 'http://webscraping.com/blog/13/', 'http://webscraping.com/blog/2/', 'http://webscraping.com/blog/3/', 'http://webscraping.com/blog/4/', 'http://webscraping.com/blog/5/', 'http://webscraping.com/blog/6/', 'http://webscraping.com/blog/7/', 'http://webscraping.com/blog/8/', 'http://webscraping.com/blog/9/', 'http://webscraping.com/blog/All-your-data-are-belong-to-us/', 'http://webscraping.com/blog/Android-Apps-Update/', 'http://webscraping.com/blog/Apple-Apps-Update/', 'http://webscraping.com/blog/Asynchronous-support-in-Python/', 'http://webscraping.com/blog/Automatic-web-scraping/', 'http://webscraping.com/blog/Automating-CAPTCHAs/', 'http://webscraping.com/blog/Automating-webkit/', 'http://webscraping.com/blog/Best-website-for-freelancers/', 'http://webscraping.com/blog/Bitcoin/', 'http://webscraping.com/blog/Caching-crawled-webpages/', 'http://webscraping.com/blog/Caching-data-efficiently/', 'http://webscraping.com/blog/Can-you-extract-data-from-this-website/', 'http://webscraping.com/blog/Client-Feedback/', 'http://webscraping.com/blog/Converting-UK-Easting-Northing-coordinates/', 'http://webscraping.com/blog/Crawling-with-threads/', 'http://webscraping.com/blog/Discount-coupons-for-data-store/', 'http://webscraping.com/blog/Extracting-article-summaries/', 'http://webscraping.com/blog/Fixed-fee-or-hourly/', 'http://webscraping.com/blog/Free-service-to-extract-article-from-webpage/', 'http://webscraping.com/blog/Generate-website-screenshot-history/', 'http://webscraping.com/blog/Google-App-Engine-limitations/', 'http://webscraping.com/blog/Google-Storage/', 'http://webscraping.com/blog/Google-interview/', 'http://webscraping.com/blog/How-to-automatically-find-contact-details/', 'http://webscraping.com/blog/How-to-crawl-websites-without-being-blocked/', 'http://webscraping.com/blog/How-to-find-what-technology-a-website-uses/', 'http://webscraping.com/blog/How-to-make-python-faster/', 'http://webscraping.com/blog/How-to-protect-your-data/', 'http://webscraping.com/blog/How-to-scrape-Android-Apps/', 'http://webscraping.com/blog/How-to-teach-yourself-web-scraping/', 'http://webscraping.com/blog/How-to-use-XPaths-robustly/', 'http://webscraping.com/blog/How-to-use-proxies/', 'http://webscraping.com/blog/I-love-AJAX/', 'http://webscraping.com/blog/Image-efficiencies/', 'http://webscraping.com/blog/Importing-CSV-into-MySQL/', 'http://webscraping.com/blog/Increase-your-Google-App-Engine-quotas-for-free/', 'http://webscraping.com/blog/Is-Web-Scraping-Legal/', 'http://webscraping.com/blog/Loading-Cookies-from-the-Browser/', 'http://webscraping.com/blog/Luminati/', 'http://webscraping.com/blog/New-scraping-quote-tool/', 'http://webscraping.com/blog/New-store-for-buying-databases/', 'http://webscraping.com/blog/Open-sourced-web-scraping-code/', 'http://webscraping.com/blog/Parsing-Flash-with-Swiffy/', 'http://webscraping.com/blog/Parsing-HTML-with-Python/', 'http://webscraping.com/blog/Rebranding-sitescraper-as-webscraping/', 'http://webscraping.com/blog/Reverse-Geocode/', 'http://webscraping.com/blog/Scraping-Flash-based-websites/', 'http://webscraping.com/blog/Scraping-JavaScript-based-web-pages-with-Chickenfoot/', 'http://webscraping.com/blog/Scraping-JavaScript-webpages-with-webkit/', 'http://webscraping.com/blog/Scraping-dynamic-data/', 'http://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/', 'http://webscraping.com/blog/Services/', 'http://webscraping.com/blog/Solving-CAPTCHA/', 'http://webscraping.com/blog/Startup/', 'http://webscraping.com/blog/Taking-advantage-of-mobile-interfaces/', 'http://webscraping.com/blog/The-SiteScraper-module/', 'http://webscraping.com/blog/Threading-with-webkit/', 'http://webscraping.com/blog/Typical-web-scraping-job/', 'http://webscraping.com/blog/UPC-Database-Update/', 'http://webscraping.com/blog/Useful-business-directories/', 'http://webscraping.com/blog/User-agents/', 'http://webscraping.com/blog/Using-Google-Cache-to-crawl-a-website/', 'http://webscraping.com/blog/Using-Google-Translate-to-crawl-a-website/', 'http://webscraping.com/blog/Using-the-internet-archive-to-crawl-a-website/', 'http://webscraping.com/blog/Web-Scraping-Interface/', 'http://webscraping.com/blog/Web-Scrapping/', 'http://webscraping.com/blog/Web-scraping-with-regular-expressions/', 'http://webscraping.com/blog/Webpage-screenshots-with-webkit/', 'http://webscraping.com/blog/What-is-CSV/', 'http://webscraping.com/blog/What-is-web-scraping/', 'http://webscraping.com/blog/Why-Google-App-Engine/', 'http://webscraping.com/blog/Why-Python/', 'http://webscraping.com/blog/Why-reinvent-the-wheel/', 'http://webscraping.com/blog/Why-web2py/', 'http://webscraping.com/blog/category/ajax', 'http://webscraping.com/blog/category/android/', 'http://webscraping.com/blog/category/beautifulsoup', 'http://webscraping.com/blog/category/big picture', 'http://webscraping.com/blog/category/business/', 'http://webscraping.com/blog/category/cache', 'http://webscraping.com/blog/category/captcha', 'http://webscraping.com/blog/category/chickenfoot', 'http://webscraping.com/blog/category/concurrent', 'http://webscraping.com/blog/category/cookies', 'http://webscraping.com/blog/category/crawling', 'http://webscraping.com/blog/category/database/', 'http://webscraping.com/blog/category/efficiency', 'http://webscraping.com/blog/category/elance', 'http://webscraping.com/blog/category/example', 'http://webscraping.com/blog/category/flash', 'http://webscraping.com/blog/category/freelancing', 'http://webscraping.com/blog/category/gae', 'http://webscraping.com/blog/category/google/', 'http://webscraping.com/blog/category/html', 'http://webscraping.com/blog/category/image', 'http://webscraping.com/blog/category/ip', 'http://webscraping.com/blog/category/ir', 'http://webscraping.com/blog/category/javascript', 'http://webscraping.com/blog/category/learn', 'http://webscraping.com/blog/category/linux', 'http://webscraping.com/blog/category/lxml', 'http://webscraping.com/blog/category/mobile', 'http://webscraping.com/blog/category/mobile apps/', 'http://webscraping.com/blog/category/ocr', 'http://webscraping.com/blog/category/opensource', 'http://webscraping.com/blog/category/proxies/', 'http://webscraping.com/blog/category/python', 'http://webscraping.com/blog/category/qt', 'http://webscraping.com/blog/category/regex', 'http://webscraping.com/blog/category/scrapy', 'http://webscraping.com/blog/category/screenshot', 'http://webscraping.com/blog/category/sitescraper', 'http://webscraping.com/blog/category/sqlite', 'http://webscraping.com/blog/category/user-agent', 'http://webscraping.com/blog/category/web2py', 'http://webscraping.com/blog/category/webkit', 'http://webscraping.com/blog/category/website/', 'http://webscraping.com/blog/category/xpath', 'http://webscraping.com/contact', 'http://webscraping.com/data', 'http://webscraping.com/data/default/database/1/belgium-zip-codes', 'http://webscraping.com/data/default/database/10/usa-restaurants', 'http://webscraping.com/data/default/database/11/android-apps', 'http://webscraping.com/data/default/database/12/universal-product-codes-upc-details', 'http://webscraping.com/data/default/database/13/international-standard-book-numbers-isbn', 'http://webscraping.com/data/default/database/14/hotel-details', 'http://webscraping.com/data/default/database/17/aircraft-models', 'http://webscraping.com/data/default/database/2/usa-cities', 'http://webscraping.com/data/default/database/23/films', 'http://webscraping.com/data/default/database/29/popular-websites', 'http://webscraping.com/data/default/database/3/world-cities', 'http://webscraping.com/data/default/database/31/german-businesses', 'http://webscraping.com/data/default/database/33/australian-businesses', 'http://webscraping.com/data/default/database/37/united-kingdom-postcodes', 'http://webscraping.com/data/default/database/4/united-kingdom-cities', 'http://webscraping.com/data/default/database/41/world-zip-codes', 'http://webscraping.com/data/default/database/5/famous-quotes', 'http://webscraping.com/data/default/database/52/universal-product-codes-upc-list', 'http://webscraping.com/data/default/database/53/summer-olympic-medals', 'http://webscraping.com/data/default/database/54/winter-olympic-medal-count', 'http://webscraping.com/data/default/database/55/song-lyrics', 'http://webscraping.com/data/default/database/57/amazon-standard-identification-numbers-asin-details', 'http://webscraping.com/data/default/database/58/salaries', 'http://webscraping.com/data/default/database/59/usa-people', 'http://webscraping.com/data/default/database/6/canada-cities', 'http://webscraping.com/data/default/database/60/blackberry-apps', 'http://webscraping.com/data/default/database/62/windows-phone-apps', 'http://webscraping.com/data/default/database/64/recipes', 'http://webscraping.com/data/default/database/65/australian-real-estate-agents', 'http://webscraping.com/data/default/database/66/european-businesses', 'http://webscraping.com/data/default/database/68/uk-businesses', 'http://webscraping.com/data/default/database/69/new-zealand-real-estate-agents', 'http://webscraping.com/data/default/database/7/apple-ios-apps', 'http://webscraping.com/data/default/database/70/usa-businesses', 'http://webscraping.com/data/default/database/71/usa-real-estate-agents', 'http://webscraping.com/data/default/database/8/amazon-standard-identification-numbers-asin', 'http://webscraping.com/data/default/database/9/world-restaurants', 'http://webscraping.com/data/default/index?page=0', 'http://webscraping.com/data/default/index?page=1', 'http://webscraping.com/data/default/index?page=2', 'http://webscraping.com/data/default/index?page=3', 'http://webscraping.com/data/default/index?page=4', 'http://webscraping.com/data/default/index?page=5', 'http://webscraping.com/data/default/index?page=6', 'http://webscraping.com/feedback', 'http://webscraping.com/quote', 'http://webscraping.com/shame']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading:', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                return download(url, user_agent, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "links = re.findall('<loc>(.*)</loc>', download('https://webscraping.com/sitemap.xml').decode())\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 5, 24, 23, 40, 36, 67718)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n",
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 2, -2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 6, 4, 10, 16, 31, 869257)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'http://www.baidu.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ffcb7bf06f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://www.baidu.com'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'http://www.baidu.com'"
     ]
    }
   ],
   "source": [
    "url = 'http://www.baidu.com'\n",
    "seen = {}\n",
    "print(seen[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.baidu.com'\n",
    "seen = {}\n",
    "print(seen.get(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-efc09b84cc65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "url = 'http://www.baidu.com'\n",
    "seen = {}\n",
    "a = seen.get(url)\n",
    "b = a + 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"country\">\n",
      " <li>\n",
      "  Area\n",
      "  <li>\n",
      "   Population\n",
      "  </li>\n",
      " </li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "broken_html = '<ul class=country><li>Area<li>Population</ul>'\n",
    "# parse the HTML\n",
    "soup = BeautifulSoup(broken_html, 'html.parser')\n",
    "fixed_html = soup.prettify()\n",
    "print(fixed_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530510536.92038"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000908851623535\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "time.sleep(10)\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.gmtime(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530514816.5389235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 5\n"
     ]
    }
   ],
   "source": [
    "def apply_async(func, args, *, callback):\n",
    "    # Compute the result\n",
    "    result = func(*args)\n",
    "\n",
    "    # Invoke the callback with the result\n",
    "    callback(result)\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    print('Got:', result)\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "apply_async(add, (2, 3), callback=print_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 5\n",
      "Got: helloworld\n"
     ]
    }
   ],
   "source": [
    "def apply_async(func, args, *, callback):\n",
    "    # Compute the result\n",
    "    result = func(*args)\n",
    "\n",
    "    # Invoke the callback with the result\n",
    "    callback(result)\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    print('Got:', result)\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "apply_async(add, (2, 3), callback=print_result)\n",
    "apply_async(add, ('hello', 'world'), callback=print_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 5\n",
      "Got: helloworld\n",
      "[1] Got: 5\n",
      "[2] Got: helloworld\n"
     ]
    }
   ],
   "source": [
    "def apply_async(func, args, *, callback):\n",
    "    # Compute the result\n",
    "    result = func(*args)\n",
    "\n",
    "    # Invoke the callback with the result\n",
    "    callback(result)\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    print('Got:', result)\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "apply_async(add, (2, 3), callback=print_result)\n",
    "apply_async(add, ('hello', 'world'), callback=print_result)\n",
    "\n",
    "\n",
    "class ResultHandler:\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.sequence = 0\n",
    "\n",
    "\tdef handler(self, result):\n",
    "\t\tself.sequence += 1\n",
    "\t\tprint('[{}] Got: {}'.format(self.sequence, result))\n",
    "\t\t\n",
    "r = ResultHandler()\n",
    "apply_async(add, (2, 3), callback=r.handler)\n",
    "apply_async(add, ('hello', 'world'), callback=r.handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 5\n",
      "Got: helloworld\n",
      "[11] Got: 5\n",
      "[12] Got: helloworld\n"
     ]
    }
   ],
   "source": [
    "def apply_async(func, args, *, callback):\n",
    "    # Compute the result\n",
    "    result = func(*args)\n",
    "\n",
    "    # Invoke the callback with the result\n",
    "    callback(result)\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    print('Got:', result)\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "apply_async(add, (2, 3), callback=print_result)\n",
    "apply_async(add, ('hello', 'world'), callback=print_result)\n",
    "\n",
    "\n",
    "def make_handler():\n",
    "\tsequence = 10\n",
    "\tdef handler(result):\n",
    "\t\tnonlocal sequence\n",
    "\t\tsequence += 1\n",
    "\t\tprint('[{}] Got: {}'.format(sequence, result))\n",
    "\treturn handler\n",
    "\n",
    "\n",
    "handler = make_handler()\n",
    "apply_async(add, (2, 3), callback=handler)\n",
    "apply_async(add, ('hello', 'world'), callback=handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 5\n",
      "Got: helloworld\n",
      "[21] Got: 5\n",
      "[22] Got: helloworld\n"
     ]
    }
   ],
   "source": [
    "def apply_async(func, args, *, callback):\n",
    "    # Compute the result\n",
    "    result = func(*args)\n",
    "\n",
    "    # Invoke the callback with the result\n",
    "    callback(result)\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    print('Got:', result)\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "apply_async(add, (2, 3), callback=print_result)\n",
    "apply_async(add, ('hello', 'world'), callback=print_result)\n",
    "\n",
    "\n",
    "def make_handler():\n",
    "\tsequence = 20\n",
    "\twhile True:\n",
    "\t\tresult = yield\n",
    "\t\tsequence += 1\n",
    "\t\tprint('[{}] Got: {}'.format(sequence, result))\n",
    "\n",
    "\n",
    "handler = make_handler()\n",
    "next(handler)  # Advance to the yield\n",
    "apply_async(add, (2, 3), callback=handler.send)\n",
    "apply_async(add, ('hello', 'world'), callback=handler.send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'get_include']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxml\n",
    "dir(lxml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CheckboxGroup',\n",
       " 'CheckboxValues',\n",
       " 'Classes',\n",
       " 'Element',\n",
       " 'FieldsDict',\n",
       " 'FormElement',\n",
       " 'HTMLParser',\n",
       " 'HtmlComment',\n",
       " 'HtmlElement',\n",
       " 'HtmlElementClassLookup',\n",
       " 'HtmlEntity',\n",
       " 'HtmlMixin',\n",
       " 'HtmlProcessingInstruction',\n",
       " 'InputElement',\n",
       " 'InputGetter',\n",
       " 'InputMixin',\n",
       " 'LabelElement',\n",
       " 'MultipleSelectOptions',\n",
       " 'MutableMapping',\n",
       " 'MutableSet',\n",
       " 'RadioGroup',\n",
       " 'SelectElement',\n",
       " 'SetMixin',\n",
       " 'TextareaElement',\n",
       " 'XHTMLParser',\n",
       " 'XHTML_NAMESPACE',\n",
       " '_MethodFunc',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__bytes_replace_meta_content_type',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__fix_docstring',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__str_replace_meta_content_type',\n",
       " '_archive_re',\n",
       " '_class_xpath',\n",
       " '_collect_string_content',\n",
       " '_contains_block_level_tag',\n",
       " '_element_name',\n",
       " '_forms_xpath',\n",
       " '_id_xpath',\n",
       " '_iter_css_imports',\n",
       " '_iter_css_urls',\n",
       " '_label_xpath',\n",
       " '_looks_like_full_html_bytes',\n",
       " '_looks_like_full_html_unicode',\n",
       " '_nons',\n",
       " '_options_xpath',\n",
       " '_parse_meta_refresh_url',\n",
       " '_rel_links_xpath',\n",
       " '_setmixin',\n",
       " '_transform_result',\n",
       " '_unquote_match',\n",
       " 'absolute_import',\n",
       " 'basestring',\n",
       " 'copy',\n",
       " 'defs',\n",
       " 'document_fromstring',\n",
       " 'etree',\n",
       " 'find_class',\n",
       " 'find_rel_links',\n",
       " 'fragment_fromstring',\n",
       " 'fragments_fromstring',\n",
       " 'fromstring',\n",
       " 'html_parser',\n",
       " 'html_to_xhtml',\n",
       " 'iterlinks',\n",
       " 'make_links_absolute',\n",
       " 'open_http_urllib',\n",
       " 'open_in_browser',\n",
       " 'parse',\n",
       " 'partial',\n",
       " 're',\n",
       " 'resolve_base_href',\n",
       " 'rewrite_links',\n",
       " 'submit_form',\n",
       " 'sys',\n",
       " 'tostring',\n",
       " 'unicode',\n",
       " 'urljoin',\n",
       " 'xhtml_parser',\n",
       " 'xhtml_to_html']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxml.html\n",
    "dir(lxml.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x14'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mac(x):\n",
    "    result = hex(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "mac(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00-00-00-00-00-1b'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mac(x):\n",
    "    '''将一个十进制数转换成一个mac地址格式'''\n",
    "    hex_x = hex(x)\n",
    "    np_x = hex_x[2:]  # no prefix\n",
    "    mac_12 = (12 - len(np_x)) * '0' + np_x\n",
    "    result = mac_12[0:2] + '-' + mac_12[2:4] + '-' + mac_12[4:6] + '-' + mac_12[6:8] + '-' + mac_12[8:10] + '-' + mac_12[10:12]\n",
    "    return result\n",
    "\n",
    "\n",
    "mac(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://example.webscraping.com\n",
      "Downloading: http://example.webscraping.com/places/default/index/1\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10 ['443 square kilometres', '86,754', 'AG', 'Antigua and Barbuda', \"St. John's\", 'NA', '.ag', 'XCD', 'Dollar', '+1-268', '', '', 'en-AG', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9 ['14,000,000 square kilometres', '0', 'AQ', 'Antarctica', '', 'AN', '.aq', '', '', '', '', '', '', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8 ['102 square kilometres', '13,254', 'AI', 'Anguilla', 'The Valley', 'NA', '.ai', 'XCD', 'Dollar', '+1-264', '', '', 'en-AI', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Angola-7 ['1,246,700 square kilometres', '13,068,161', 'AO', 'Angola', 'Luanda', 'AF', '.ao', 'AOA', 'Kwanza', '244', '', '', 'pt-AO', 'CD NA ZM CG ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Andorra-6 ['468 square kilometres', '84,000', 'AD', 'Andorra', 'Andorra la Vella', 'EU', '.ad', 'EUR', 'Euro', '376', 'AD###', '^(?:AD)*(\\\\d{3})$', 'ca', 'ES FR ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5 ['199 square kilometres', '57,881', 'AS', 'American Samoa', 'Pago Pago', 'OC', '.as', 'USD', 'Dollar', '+1-684', '', '', 'en-AS,sm,to', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/Algeria-4 ['2,381,740 square kilometres', '34,586,184', 'DZ', 'Algeria', 'Algiers', 'AF', '.dz', 'DZD', 'Dinar', '213', '#####', '^(\\\\d{5})$', 'ar-DZ', 'NE EH LY MR TN MA ML ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Albania-3 ['28,748 square kilometres', '2,986,952', 'AL', 'Albania', 'Tirana', 'EU', '.al', 'ALL', 'Lek', '355', '', '', 'sq,el', 'MK GR CS ME RS XK ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2 ['1,580 square kilometres', '26,711', 'AX', 'Aland Islands', 'Mariehamn', 'EU', '.ax', 'EUR', 'Euro', '+358-18', '#####', '^(?:FI)*(\\\\d{5})$', 'sv-AX', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1 ['647,500 square kilometres', '29,121,286', 'AF', 'Afghanistan', 'Kabul', 'AS', '.af', 'AFN', 'Afghani', '93', '', '', 'fa-AF,ps,uz-AF,tk', 'TM CN IR TJ PK UZ ']\n",
      "Downloading: http://example.webscraping.com/places/default/index\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import datetime\n",
    "import lxml.html\n",
    "import re\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import urllib.robotparser\n",
    "import sys\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('http://example.webscraping.com/robots.txt')\n",
    "rp.read()\n",
    "proxy = None\n",
    "\n",
    "\n",
    "class Throttle:\n",
    "    \"\"\"Add a delay between downloads to the same domain\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delay):\n",
    "        # amount of delay between downloads for each domain\n",
    "        self.delay = delay\n",
    "        # timestamp of when a domain was last accessed\n",
    "        self.domains = {}\n",
    "\n",
    "    def wait(self, url):\n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        last_accessed = self.domains.get(domain)\n",
    "        if self.delay > 0 and last_accessed is not None:\n",
    "            sleep_secs = self.delay - \\\n",
    "                (datetime.datetime.now() - last_accessed).seconds\n",
    "            if sleep_secs > 0:\n",
    "                # domain has been accessed recently\n",
    "                # so need to sleep\n",
    "                time.sleep(sleep_secs)\n",
    "        # update the last accessed time\n",
    "        self.domains[domain] = datetime.datetime.now()\n",
    "\n",
    "        \n",
    "throttle=Throttle(1)\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', proxy=None, num_retries=2):\n",
    "    '''Support custom User-Agent, proxy and auto retry\n",
    "    '''\n",
    "    print('Downloading:', url)  # url is download function's first arguments\n",
    "    headers = {'User-agent': user_agent}  # user_agent is the second arguments\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener()\n",
    "    if proxy:\n",
    "        proxy_params = {urllib.parse.urlparse(url).scheme: proxy}\n",
    "        opener.add_handler(urllib.request.ProxyHandler(proxy_params))\n",
    "    try:\n",
    "        html = opener.open(request).read().decode()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                html = download(url, user_agent, proxy, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "def link_crawler(seed_url, link_regex, max_depth=2, scrape_callback=None):\n",
    "    \"\"\"Crawl from the given seed URL following links matched by link_regex\n",
    "    \"\"\"\n",
    "    crawl_queue = [seed_url]\n",
    "    # keep track which URL's have seen before\n",
    "    seen = {seed_url: 0}\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        # check url passes robots.txt restrictions\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            throttle.wait(url)\n",
    "            html = download(url, user_agent, proxy, 2)\n",
    "            links = []\n",
    "            if scrape_callback:\n",
    "            \tlinks.extend(scrape_callback(url, html) or [])\n",
    "        else:\n",
    "            print('Blocked by robots.txt:', url)\n",
    "            html = None\n",
    "            sys.exit()\n",
    "        # filter for links matching our regular expression\n",
    "        depth = seen[url]\n",
    "        if depth != max_depth:\n",
    "            for link in get_links(html):\n",
    "                # check if link matches expected regex\n",
    "                if re.match(link_regex, link):\n",
    "                    # form absolute link\n",
    "                    link = urllib.parse.urljoin(seed_url, link)\n",
    "                    # check if have already seen this link\n",
    "                    if link not in seen:\n",
    "                        seen[link] = depth + 1\n",
    "                        crawl_queue.append(link)\n",
    "\n",
    "\n",
    "def get_links(html):\n",
    "    \"\"\"Return a list of links from html\n",
    "    \"\"\"\n",
    "    # a regular expression to extract all links from the webpage\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)\n",
    "    # list of all links from the webpage\n",
    "    return webpage_regex.findall(html)\n",
    "\n",
    "\n",
    "FIELDS = ('area', 'population', 'iso', 'country', 'capital', 'continent', 'tld', 'currency_code', 'currency_name', 'phone', 'postal_code_format', 'postal_code_regex', 'languages', 'neighbours')\n",
    "\n",
    "\n",
    "def scrape_callback(url, html):\n",
    "\tif re.search('/view/', url):\n",
    "\t\ttree = lxml.html.fromstring(html)\n",
    "\t\trow = [tree.cssselect('table > tr#places_%s__row > td.w2p_fw' % field)[0].text_content() for field in FIELDS]\n",
    "\t\tprint(url, row)\n",
    "\n",
    "\n",
    "link_crawler('http://example.webscraping.com', '/places/default/(index|view)', 1, scrape_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-52c7b74b8e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://example.webscraping.com\n",
      "Downloading: http://example.webscraping.com/places/default/index/1\n",
      "Downloading: http://example.webscraping.com/places/default/index/2\n",
      "Downloading: http://example.webscraping.com/places/default/index/0\n",
      "Downloading: http://example.webscraping.com/places/default/view/Barbados-20\n",
      "http://example.webscraping.com/places/default/view/Barbados-20 ['431 square kilometres', '285,653', 'BB', 'Barbados', 'Bridgetown', 'NA', '.bb', 'BBD', 'Dollar', '+1-246', 'BB#####', '^(?:BB)*(\\\\d{5})$', 'en-BB', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bangladesh-19\n",
      "http://example.webscraping.com/places/default/view/Bangladesh-19 ['144,000 square kilometres', '156,118,464', 'BD', 'Bangladesh', 'Dhaka', 'AS', '.bd', 'BDT', 'Taka', '880', '####', '^(\\\\d{4})$', 'bn-BD,en', 'MM IN ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bahrain-18\n",
      "http://example.webscraping.com/places/default/view/Bahrain-18 ['665 square kilometres', '738,004', 'BH', 'Bahrain', 'Manama', 'AS', '.bh', 'BHD', 'Dinar', '973', '####|###', '^(\\\\d{3}\\\\d?)$', 'ar-BH,en,fa,ur', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bahamas-17\n",
      "http://example.webscraping.com/places/default/view/Bahamas-17 ['13,940 square kilometres', '301,790', 'BS', 'Bahamas', 'Nassau', 'NA', '.bs', 'BSD', 'Dollar', '+1-242', '', '', 'en-BS', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Azerbaijan-16\n",
      "http://example.webscraping.com/places/default/view/Azerbaijan-16 ['86,600 square kilometres', '8,303,512', 'AZ', 'Azerbaijan', 'Baku', 'AS', '.az', 'AZN', 'Manat', '994', 'AZ ####', '^(?:AZ)*(\\\\d{4})$', 'az,ru,hy', 'GE IR AM TR RU ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Austria-15\n",
      "http://example.webscraping.com/places/default/view/Austria-15 ['83,858 square kilometres', '8,205,000', 'AT', 'Austria', 'Vienna', 'EU', '.at', 'EUR', 'Euro', '43', '####', '^(\\\\d{4})$', 'de-AT,hr,hu,sl', 'CH DE HU SK CZ IT SI LI ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Australia-14\n",
      "http://example.webscraping.com/places/default/view/Australia-14 ['7,686,850 square kilometres', '21,515,754', 'AU', 'Australia', 'Canberra', 'OC', '.au', 'AUD', 'Dollar', '61', '####', '^(\\\\d{4})$', 'en-AU', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Aruba-13\n",
      "http://example.webscraping.com/places/default/view/Aruba-13 ['193 square kilometres', '71,566', 'AW', 'Aruba', 'Oranjestad', 'NA', '.aw', 'AWG', 'Guilder', '297', '', '', 'nl-AW,es,en', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Armenia-12\n",
      "http://example.webscraping.com/places/default/view/Armenia-12 ['29,800 square kilometres', '2,968,000', 'AM', 'Armenia', 'Yerevan', 'AS', '.am', 'AMD', 'Dram', '374', '######', '^(\\\\d{6})$', 'hy', 'GE IR AZ TR ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Argentina-11\n",
      "http://example.webscraping.com/places/default/view/Argentina-11 ['2,766,890 square kilometres', '41,343,201', 'AR', 'Argentina', 'Buenos Aires', 'SA', '.ar', 'ARS', 'Peso', '54', '@####@@@', '^([A-Z]\\\\d{4}[A-Z]{3})$', 'es-AR,en,it,de,fr,gn', 'CL BO UY PY BR ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10 ['443 square kilometres', '86,754', 'AG', 'Antigua and Barbuda', \"St. John's\", 'NA', '.ag', 'XCD', 'Dollar', '+1-268', '', '', 'en-AG', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9 ['14,000,000 square kilometres', '0', 'AQ', 'Antarctica', '', 'AN', '.aq', '', '', '', '', '', '', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8 ['102 square kilometres', '13,254', 'AI', 'Anguilla', 'The Valley', 'NA', '.ai', 'XCD', 'Dollar', '+1-264', '', '', 'en-AI', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Angola-7 ['1,246,700 square kilometres', '13,068,161', 'AO', 'Angola', 'Luanda', 'AF', '.ao', 'AOA', 'Kwanza', '244', '', '', 'pt-AO', 'CD NA ZM CG ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Andorra-6 ['468 square kilometres', '84,000', 'AD', 'Andorra', 'Andorra la Vella', 'EU', '.ad', 'EUR', 'Euro', '376', 'AD###', '^(?:AD)*(\\\\d{3})$', 'ca', 'ES FR ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5 ['199 square kilometres', '57,881', 'AS', 'American Samoa', 'Pago Pago', 'OC', '.as', 'USD', 'Dollar', '+1-684', '', '', 'en-AS,sm,to', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/Algeria-4 ['2,381,740 square kilometres', '34,586,184', 'DZ', 'Algeria', 'Algiers', 'AF', '.dz', 'DZD', 'Dinar', '213', '#####', '^(\\\\d{5})$', 'ar-DZ', 'NE EH LY MR TN MA ML ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Albania-3 ['28,748 square kilometres', '2,986,952', 'AL', 'Albania', 'Tirana', 'EU', '.al', 'ALL', 'Lek', '355', '', '', 'sq,el', 'MK GR CS ME RS XK ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2 ['1,580 square kilometres', '26,711', 'AX', 'Aland Islands', 'Mariehamn', 'EU', '.ax', 'EUR', 'Euro', '+358-18', '#####', '^(?:FI)*(\\\\d{5})$', 'sv-AX', ' ']\n",
      "Downloading: http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1 ['647,500 square kilometres', '29,121,286', 'AF', 'Afghanistan', 'Kabul', 'AS', '.af', 'AFN', 'Afghani', '93', '', '', 'fa-AF,ps,uz-AF,tk', 'TM CN IR TJ PK UZ ']\n",
      "Downloading: http://example.webscraping.com/places/default/index\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import datetime\n",
    "import lxml.html\n",
    "import re\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import urllib.robotparser\n",
    "import sys\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('http://example.webscraping.com/robots.txt')\n",
    "rp.read()\n",
    "proxy = None\n",
    "\n",
    "\n",
    "class Throttle:\n",
    "    \"\"\"Add a delay between downloads to the same domain\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delay):\n",
    "        # amount of delay between downloads for each domain\n",
    "        self.delay = delay\n",
    "        # timestamp of when a domain was last accessed\n",
    "        self.domains = {}\n",
    "\n",
    "    def wait(self, url):\n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        last_accessed = self.domains.get(domain)\n",
    "        if self.delay > 0 and last_accessed is not None:\n",
    "            sleep_secs = self.delay - \\\n",
    "                (datetime.datetime.now() - last_accessed).seconds\n",
    "            if sleep_secs > 0:\n",
    "                # domain has been accessed recently\n",
    "                # so need to sleep\n",
    "                time.sleep(sleep_secs)\n",
    "        # update the last accessed time\n",
    "        self.domains[domain] = datetime.datetime.now()\n",
    "\n",
    "        \n",
    "throttle=Throttle(1)\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', proxy=None, num_retries=2):\n",
    "    '''Support custom User-Agent, proxy and auto retry\n",
    "    '''\n",
    "    print('Downloading:', url)  # url is download function's first arguments\n",
    "    headers = {'User-agent': user_agent}  # user_agent is the second arguments\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener()\n",
    "    if proxy:\n",
    "        proxy_params = {urllib.parse.urlparse(url).scheme: proxy}\n",
    "        opener.add_handler(urllib.request.ProxyHandler(proxy_params))\n",
    "    try:\n",
    "        html = opener.open(request).read().decode()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                html = download(url, user_agent, proxy, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "def link_crawler(seed_url, link_regex, max_depth=2, scrape_callback=None):\n",
    "    \"\"\"Crawl from the given seed URL following links matched by link_regex\n",
    "    \"\"\"\n",
    "    crawl_queue = [seed_url]\n",
    "    # keep track which URL's have seen before\n",
    "    seen = {seed_url: 0}\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        # check url passes robots.txt restrictions\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            throttle.wait(url)\n",
    "            html = download(url, user_agent, proxy, 2)\n",
    "            links = []\n",
    "            if scrape_callback:\n",
    "            \tlinks.extend(scrape_callback(url, html) or [])\n",
    "        else:\n",
    "            print('Blocked by robots.txt:', url)\n",
    "            html = None\n",
    "            sys.exit()\n",
    "        # filter for links matching our regular expression\n",
    "        depth = seen[url]\n",
    "        if depth != max_depth:\n",
    "            for link in get_links(html):\n",
    "                # check if link matches expected regex\n",
    "                if re.match(link_regex, link):\n",
    "                    # form absolute link\n",
    "                    link = urllib.parse.urljoin(seed_url, link)\n",
    "                    # check if have already seen this link\n",
    "                    if link not in seen:\n",
    "                        seen[link] = depth + 1\n",
    "                        crawl_queue.append(link)\n",
    "\n",
    "\n",
    "def get_links(html):\n",
    "    \"\"\"Return a list of links from html\n",
    "    \"\"\"\n",
    "    # a regular expression to extract all links from the webpage\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)\n",
    "    # list of all links from the webpage\n",
    "    return webpage_regex.findall(html)\n",
    "\n",
    "\n",
    "FIELDS = ('area', 'population', 'iso', 'country', 'capital', 'continent', 'tld', 'currency_code', 'currency_name', 'phone', 'postal_code_format', 'postal_code_regex', 'languages', 'neighbours')\n",
    "\n",
    "\n",
    "def scrape_callback(url, html):\n",
    "\tif re.search('/view/', url):\n",
    "\t\ttree = lxml.html.fromstring(html)\n",
    "\t\trow = [tree.cssselect('table > tr#places_%s__row > td.w2p_fw' % field)[0].text_content() for field in FIELDS]\n",
    "\t\tprint(url, row)\n",
    "\n",
    "\n",
    "link_crawler('http://example.webscraping.com', '/places/default/(index|view)', scrape_callback=scrape_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import urllib.robotparser\n",
    "import sys\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('http://example.webscraping.com/robots.txt')\n",
    "rp.read()\n",
    "proxy = None\n",
    "\n",
    "\n",
    "class Throttle:\n",
    "    \"\"\"Add a delay between downloads to the same domain\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delay):\n",
    "        # amount of delay between downloads for each domain\n",
    "        self.delay = delay\n",
    "        # timestamp of when a domain was last accessed\n",
    "        self.domains = {}\n",
    "\n",
    "    def wait(self, url):\n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        last_accessed = self.domains.get(domain)\n",
    "        if self.delay > 0 and last_accessed is not None:\n",
    "            sleep_secs = self.delay - \\\n",
    "                (datetime.datetime.now() - last_accessed).seconds\n",
    "            if sleep_secs > 0:\n",
    "                # domain has been accessed recently\n",
    "                # so need to sleep\n",
    "                time.sleep(sleep_secs)\n",
    "        # update the last accessed time\n",
    "        self.domains[domain] = datetime.datetime.now()\n",
    "\n",
    "        \n",
    "throttle=Throttle(1)\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', proxy=None, num_retries=2):\n",
    "    '''Support custom User-Agent, proxy and auto retry\n",
    "    '''\n",
    "    print('Downloading:', url)  # url is download function's first arguments\n",
    "    headers = {'User-agent': user_agent}  # user_agent is the second arguments\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener()\n",
    "    if proxy:\n",
    "        proxy_params = {urllib.parse.urlparse(url).scheme: proxy}\n",
    "        opener.add_handler(urllib.request.ProxyHandler(proxy_params))\n",
    "    try:\n",
    "        html = opener.open(request).read().decode()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                html = download(url, user_agent, proxy, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "def link_crawler(seed_url, link_regex, max_depth=2, scrape_callback=None):\n",
    "    \"\"\"Crawl from the given seed URL following links matched by link_regex\n",
    "    \"\"\"\n",
    "    crawl_queue = [seed_url]\n",
    "    # keep track which URL's have seen before\n",
    "    seen = {seed_url: 0}\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        # check url passes robots.txt restrictions\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            throttle.wait(url)\n",
    "            html = download(url, user_agent, proxy, 2)\n",
    "            links = []\n",
    "            if scrape_callback:\n",
    "                links.extend(scrape_callback(url, html) or [])\n",
    "        else:\n",
    "            print('Blocked by robots.txt:', url)\n",
    "            html = None\n",
    "            sys.exit()\n",
    "        # filter for links matching our regular expression\n",
    "        depth = seen[url]\n",
    "        if depth != max_depth:\n",
    "            for link in get_links(html):\n",
    "                # check if link matches expected regex\n",
    "                if re.match(link_regex, link):\n",
    "                    # form absolute link\n",
    "                    link = urllib.parse.urljoin(seed_url, link)\n",
    "                    # check if have already seen this link\n",
    "                    if link not in seen:\n",
    "                        seen[link] = depth + 1\n",
    "                        crawl_queue.append(link)\n",
    "\n",
    "\n",
    "def get_links(html):\n",
    "    \"\"\"Return a list of links from html\n",
    "    \"\"\"\n",
    "    # a regular expression to extract all links from the webpage\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)\n",
    "    # list of all links from the webpage\n",
    "    return webpage_regex.findall(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://example.webscraping.com\n",
      "Downloading: http://example.webscraping.com/places/default/index/1\n",
      "Downloading: http://example.webscraping.com/places/default/index/2\n",
      "Downloading: http://example.webscraping.com/places/default/index/0\n",
      "Downloading: http://example.webscraping.com/places/default/view/Barbados-20\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bangladesh-19\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bahrain-18\n",
      "Downloading: http://example.webscraping.com/places/default/view/Bahamas-17\n",
      "Downloading: http://example.webscraping.com/places/default/view/Azerbaijan-16\n",
      "Downloading: http://example.webscraping.com/places/default/view/Austria-15\n",
      "Downloading: http://example.webscraping.com/places/default/view/Australia-14\n",
      "Downloading: http://example.webscraping.com/places/default/view/Aruba-13\n",
      "Downloading: http://example.webscraping.com/places/default/view/Armenia-12\n",
      "Downloading: http://example.webscraping.com/places/default/view/Argentina-11\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "Downloading: http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "Downloading: http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "Downloading: http://example.webscraping.com/places/default/view/Angola-7\n",
      "Downloading: http://example.webscraping.com/places/default/view/Andorra-6\n",
      "Downloading: http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "Downloading: http://example.webscraping.com/places/default/view/Algeria-4\n",
      "Downloading: http://example.webscraping.com/places/default/view/Albania-3\n",
      "Downloading: http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "Downloading: http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "Downloading: http://example.webscraping.com/places/default/index\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import lxml.html\n",
    "import re\n",
    "\n",
    "\n",
    "class ScrapeCallback:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.writer = csv.writer(open('countries.csv', 'w'))\n",
    "        self.fields = ('area', 'population', 'iso', 'country', 'capital',\n",
    "                       'continent', 'tld', 'currency_code', 'currency_name',\n",
    "                       'phone', 'postal_code_format', 'postal_code_regex',\n",
    "                       'languages', 'neighbours')\n",
    "        self.writer.writerow(self.fields)\n",
    "\n",
    "    def __call__(self, url, html):\n",
    "        if re.search('/view/', url):\n",
    "            tree = lxml.html.fromstring(html)\n",
    "            row = []\n",
    "            for field in self.fields:\n",
    "                row.append(tree.cssselect(\n",
    "                    'table > tr#places_{}__row > td.w2p_fw'.format(field))[0].text_content())\n",
    "            self.writer.writerow(row)\n",
    "\n",
    "\n",
    "link_crawler('http://example.webscraping.com', '/places/default/(index|view)',\n",
    "                 scrape_callback=ScrapeCallback())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import urllib.robotparser\n",
    "import sys\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('http://example.webscraping.com/robots.txt')\n",
    "rp.read()\n",
    "proxy = None\n",
    "\n",
    "\n",
    "class Throttle:\n",
    "    \"\"\"Add a delay between downloads to the same domain\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delay):\n",
    "        # amount of delay between downloads for each domain\n",
    "        self.delay = delay\n",
    "        # timestamp of when a domain was last accessed\n",
    "        self.domains = {}\n",
    "\n",
    "    def wait(self, url):\n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        last_accessed = self.domains.get(domain)\n",
    "        if self.delay > 0 and last_accessed is not None:\n",
    "            sleep_secs = self.delay - \\\n",
    "                (datetime.datetime.now() - last_accessed).seconds\n",
    "            if sleep_secs > 0:\n",
    "                # domain has been accessed recently\n",
    "                # so need to sleep\n",
    "                time.sleep(sleep_secs)\n",
    "        # update the last accessed time\n",
    "        self.domains[domain] = datetime.datetime.now()\n",
    "\n",
    "        \n",
    "throttle=Throttle(1)\n",
    "\n",
    "\n",
    "def download(url, user_agent='wswp', proxy=None, num_retries=2):\n",
    "    '''Support custom User-Agent, proxy and auto retry\n",
    "    '''\n",
    "    # print('Downloading:', url)  # url is download function's first arguments\n",
    "    headers = {'User-agent': user_agent}  # user_agent is the second arguments\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener()\n",
    "    if proxy:\n",
    "        proxy_params = {urllib.parse.urlparse(url).scheme: proxy}\n",
    "        opener.add_handler(urllib.request.ProxyHandler(proxy_params))\n",
    "    try:\n",
    "        html = opener.open(request).read().decode()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error:', e.reason)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                # retry 5XX HTTP errors\n",
    "                html = download(url, user_agent, proxy, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "\n",
    "def link_crawler(seed_url, link_regex, max_depth=2, scrape_callback=None):\n",
    "    \"\"\"Crawl from the given seed URL following links matched by link_regex\n",
    "    \"\"\"\n",
    "    crawl_queue = [seed_url]\n",
    "    # keep track which URL's have seen before\n",
    "    seen = {seed_url: 0}\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        # check url passes robots.txt restrictions\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            throttle.wait(url)\n",
    "            html = download(url, user_agent, proxy, 2)\n",
    "            links = []\n",
    "            if scrape_callback:\n",
    "                links.extend(scrape_callback(url, html) or [])\n",
    "        else:\n",
    "            print('Blocked by robots.txt:', url)\n",
    "            html = None\n",
    "            sys.exit()\n",
    "        # filter for links matching our regular expression\n",
    "        depth = seen[url]\n",
    "        if depth != max_depth:\n",
    "            for link in get_links(html):\n",
    "                # check if link matches expected regex\n",
    "                if re.match(link_regex, link):\n",
    "                    # form absolute link\n",
    "                    link = urllib.parse.urljoin(seed_url, link)\n",
    "                    # check if have already seen this link\n",
    "                    if link not in seen:\n",
    "                        seen[link] = depth + 1\n",
    "                        crawl_queue.append(link)\n",
    "\n",
    "\n",
    "def get_links(html):\n",
    "    \"\"\"Return a list of links from html\n",
    "    \"\"\"\n",
    "    # a regular expression to extract all links from the webpage\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)\n",
    "    # list of all links from the webpage\n",
    "    return webpage_regex.findall(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import lxml.html\n",
    "import re\n",
    "\n",
    "\n",
    "class ScrapeCallback:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.writer = csv.writer(open('countries.csv', 'w'))\n",
    "        self.fields = ('area', 'population', 'iso', 'country', 'capital',\n",
    "                       'continent', 'tld', 'currency_code', 'currency_name',\n",
    "                       'phone', 'postal_code_format', 'postal_code_regex',\n",
    "                       'languages', 'neighbours')\n",
    "        self.writer.writerow(self.fields)\n",
    "\n",
    "    def __call__(self, url, html):\n",
    "        if re.search('/view/', url):\n",
    "            tree = lxml.html.fromstring(html)\n",
    "            row = []\n",
    "            for field in self.fields:\n",
    "                row.append(tree.cssselect(\n",
    "                    'table > tr#places_{}__row > td.w2p_fw'.format(field))[0].text_content())\n",
    "            self.writer.writerow(row)\n",
    "\n",
    "\n",
    "link_crawler('http://example.webscraping.com', '/places/default/(index|view)', max_depth=-1,\n",
    "                 scrape_callback=ScrapeCallback())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_elementpath',\n",
       " 'cssselect',\n",
       " 'etree',\n",
       " 'get_include',\n",
       " 'html']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxml\n",
    "dir(lxml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CheckboxGroup',\n",
       " 'CheckboxValues',\n",
       " 'Classes',\n",
       " 'Element',\n",
       " 'FieldsDict',\n",
       " 'FormElement',\n",
       " 'HTMLParser',\n",
       " 'HtmlComment',\n",
       " 'HtmlElement',\n",
       " 'HtmlElementClassLookup',\n",
       " 'HtmlEntity',\n",
       " 'HtmlMixin',\n",
       " 'HtmlProcessingInstruction',\n",
       " 'InputElement',\n",
       " 'InputGetter',\n",
       " 'InputMixin',\n",
       " 'LabelElement',\n",
       " 'MultipleSelectOptions',\n",
       " 'MutableMapping',\n",
       " 'MutableSet',\n",
       " 'RadioGroup',\n",
       " 'SelectElement',\n",
       " 'SetMixin',\n",
       " 'TextareaElement',\n",
       " 'XHTMLParser',\n",
       " 'XHTML_NAMESPACE',\n",
       " '_MethodFunc',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__bytes_replace_meta_content_type',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__fix_docstring',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__str_replace_meta_content_type',\n",
       " '_archive_re',\n",
       " '_class_xpath',\n",
       " '_collect_string_content',\n",
       " '_contains_block_level_tag',\n",
       " '_element_name',\n",
       " '_forms_xpath',\n",
       " '_id_xpath',\n",
       " '_iter_css_imports',\n",
       " '_iter_css_urls',\n",
       " '_label_xpath',\n",
       " '_looks_like_full_html_bytes',\n",
       " '_looks_like_full_html_unicode',\n",
       " '_nons',\n",
       " '_options_xpath',\n",
       " '_parse_meta_refresh_url',\n",
       " '_rel_links_xpath',\n",
       " '_setmixin',\n",
       " '_transform_result',\n",
       " '_unquote_match',\n",
       " 'absolute_import',\n",
       " 'basestring',\n",
       " 'copy',\n",
       " 'defs',\n",
       " 'document_fromstring',\n",
       " 'etree',\n",
       " 'find_class',\n",
       " 'find_rel_links',\n",
       " 'fragment_fromstring',\n",
       " 'fragments_fromstring',\n",
       " 'fromstring',\n",
       " 'html_parser',\n",
       " 'html_to_xhtml',\n",
       " 'iterlinks',\n",
       " 'make_links_absolute',\n",
       " 'open_http_urllib',\n",
       " 'open_in_browser',\n",
       " 'parse',\n",
       " 'partial',\n",
       " 're',\n",
       " 'resolve_base_href',\n",
       " 'rewrite_links',\n",
       " 'submit_form',\n",
       " 'sys',\n",
       " 'tostring',\n",
       " 'unicode',\n",
       " 'urljoin',\n",
       " 'xhtml_parser',\n",
       " 'xhtml_to_html']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxml.html\n",
    "dir(lxml.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!--[if HTML5]><![endif]-->\n",
      "<!DOCTYPE html>\n",
      "<!-- paulirish.com/2008/conditional-stylesheets-vs-css-hacks-answer-neither/ -->\n",
      "<!--[if lt IE 7]><html class=\"ie ie6 ie-lte9 ie-lte8 ie-lte7 no-js\" lang=\"en-us\"> <![endif]-->\n",
      "<!--[if IE 7]><html class=\"ie ie7 ie-lte9 ie-lte8 ie-lte7 no-js\" lang=\"en-us\"> <![endif]-->\n",
      "<!--[if IE 8]><html class=\"ie ie8 ie-lte9 ie-lte8 no-js\" lang=\"en-us\"> <![endif]-->\n",
      "<!--[if IE 9]><html class=\"ie9 ie-lte9 no-js\" lang=\"en-us\"> <![endif]-->\n",
      "<!--[if (gt IE 9)|!(IE)]><!--> <html class=\"no-js\" lang=\"en-us\"> <!--<![endif]-->\n",
      "<head>\n",
      "<title>Example web scraping website</title>\n",
      "  <!--[if !HTML5]>\n",
      "      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
      "  <![endif]-->\n",
      "  <!-- www.phpied.com/conditional-comments-block-downloads/ -->\n",
      "  <!-- Always force latest IE rendering engine\n",
      "       (even in intranet) & Chrome Frame\n",
      "       Remove this if you use the .htaccess -->\n",
      "\t   \n",
      "  <meta charset=\"utf-8\" />\n",
      "\n",
      "  <!-- http://dev.w3.org/html5/markup/meta.name.html -->\n",
      "  <meta name=\"application-name\" content=\"places\" />\n",
      "\n",
      "  <!--  Mobile Viewport Fix\n",
      "        j.mp/mobileviewport & davidbcalhoun.com/2010/viewport-metatag\n",
      "        device-width: Occupy full width of the screen in its current orientation\n",
      "        initial-scale = 1.0 retains dimensions instead of zooming out if page height > device height\n",
      "        user-scalable = yes allows the user to zoom in -->\n",
      "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "\n",
      "  <link rel=\"shortcut icon\" href=\"/places/static/images/favicon.ico\" type=\"image/x-icon\">\n",
      "  <link rel=\"apple-touch-icon\" href=\"/places/static/images/favicon.png\">\n",
      "\n",
      "  <!-- All JavaScript at the bottom, except for Modernizr which enables\n",
      "       HTML5 elements & feature detects -->\n",
      "  <script src=\"/places/static/js/modernizr.custom.js\"></script>\n",
      "\n",
      "  <!-- include stylesheets -->\n",
      "  \n",
      "\n",
      "  <script type=\"text/javascript\"><!--\n",
      "    // These variables are used by the web2py_ajax_init function in web2py_ajax.js (which is loaded below).\n",
      "    var w2p_ajax_confirm_message = \"Are you sure you want to delete this object?\";\n",
      "    var w2p_ajax_disable_with_message = \"Working...\";\n",
      "    var w2p_ajax_date_format = \"%Y-%m-%d\";\n",
      "    var w2p_ajax_datetime_format = \"%Y-%m-%d %H:%M:%S\";\n",
      "    var ajax_error_500 = 'An error occured, please <a href=\"/places/default/view/United-Kingdom-239\">reload</a> the page'\n",
      "    //--></script>\n",
      "\n",
      "<meta name=\"keywords\" content=\"web2py, python, web scraping\" />\n",
      "<meta name=\"generator\" content=\"Web2py Web Framework\" />\n",
      "<meta name=\"author\" content=\"Richard Penman\" />\n",
      "<script src=\"/places/static/js/jquery.js\" type=\"text/javascript\"></script><link href=\"/places/static/css/calendar.css\" rel=\"stylesheet\" type=\"text/css\" /><script src=\"/places/static/js/calendar.js\" type=\"text/javascript\"></script><script src=\"/places/static/js/web2py.js\" type=\"text/javascript\"></script><link href=\"/places/static/css/web2py.css\" rel=\"stylesheet\" type=\"text/css\" /><link href=\"/places/static/css/bootstrap.min.css\" rel=\"stylesheet\" type=\"text/css\" /><link href=\"/places/static/css/bootstrap-responsive.min.css\" rel=\"stylesheet\" type=\"text/css\" /><link href=\"/places/static/css/style.css\" rel=\"stylesheet\" type=\"text/css\" /><link href=\"/places/static/css/web2py_bootstrap.css\" rel=\"stylesheet\" type=\"text/css\" />\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "  <!-- uncomment here to load jquery-ui\n",
      "       <link rel=\"stylesheet\" href=\"http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/themes/ui-lightness/jquery-ui.css\" type=\"text/css\" media=\"all\" />\n",
      "       <script src=\"http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.min.js\" type=\"text/javascript\"></script>\n",
      "       uncomment to load jquery-ui //-->\n",
      "  <noscript><link href=\"/places/static/css/web2py_bootstrap_nojs.css\" rel=\"stylesheet\" type=\"text/css\" /></noscript>\n",
      "  \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "  <!-- Navbar ================================================== -->\n",
      "  <div class=\"navbar navbar-inverse\">\n",
      "    <div class=\"flash\"></div>\n",
      "    <div class=\"navbar-inner\">\n",
      "      <div class=\"container\">\n",
      "        \n",
      "        <!-- the next tag is necessary for bootstrap menus, do not remove -->\n",
      "        <button type=\"button\" class=\"btn btn-navbar\" data-toggle=\"collapse\" data-target=\".nav-collapse\" style=\"display:none;\">\n",
      "          <span class=\"icon-bar\"></span>\n",
      "          <span class=\"icon-bar\"></span>\n",
      "          <span class=\"icon-bar\"></span>\n",
      "        </button>\n",
      "        \n",
      "        <ul id=\"navbar\" class=\"nav pull-right\"><li class=\"dropdown\"><a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\" rel=\"nofollow\">Log In</a><ul class=\"dropdown-menu\"><li><a href=\"/places/default/user/register?_next=/places/default/view/United-Kingdom-239\" rel=\"nofollow\"><i class=\"icon icon-user glyphicon glyphicon-user\"></i> Sign Up</a></li><li class=\"divider\"></li><li><a href=\"/places/default/user/login?_next=/places/default/view/United-Kingdom-239\" rel=\"nofollow\"><i class=\"icon icon-off glyphicon glyphicon-off\"></i> Log In</a></li></ul></li></ul>\n",
      "        <div class=\"nav\">\n",
      "          \n",
      "          <ul class=\"nav\"><li class=\"web2py-menu-first\"><a href=\"/places/default/index\">Home</a></li><li class=\"web2py-menu-last\"><a href=\"/places/default/search\">Search</a></li></ul>\n",
      "          \n",
      "        </div><!--/.nav-collapse -->\n",
      "      </div>\n",
      "    </div>\n",
      "  </div><!--/top navbar -->\n",
      "\n",
      "  <div class=\"container\">\n",
      "    <!-- Masthead ================================================== -->\n",
      "      \n",
      "    <header class=\"mastheader row\" id=\"header\">\n",
      "        <div class=\"span12\">\n",
      "            <div class=\"page-header\">\n",
      "                <h1>\n",
      "                    Example web scraping website\n",
      "                    <small></small>\n",
      "                </h1>\n",
      "            </div>\n",
      "        </div>\n",
      "    </header>\n",
      "\t\n",
      "\n",
      "    <section id=\"main\" class=\"main row\">\n",
      "        \n",
      "\n",
      "        <div class=\"span12\">\n",
      "            \n",
      "            \n",
      "\n",
      "<form action=\"#\" enctype=\"multipart/form-data\" method=\"post\"><table><tr id=\"places_national_flag__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_national_flag\" id=\"places_national_flag__label\">National Flag: </label></td><td class=\"w2p_fw\"><img src=\"/places/static/images/flags/gb.png\" /></td><td class=\"w2p_fc\"></td></tr><tr id=\"places_area__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_area\" id=\"places_area__label\">Area: </label></td><td class=\"w2p_fw\">244,820 square kilometres</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_population__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_population\" id=\"places_population__label\">Population: </label></td><td class=\"w2p_fw\">62,348,447</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_iso__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_iso\" id=\"places_iso__label\">Iso: </label></td><td class=\"w2p_fw\">GB</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_country__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_country\" id=\"places_country__label\">Country: </label></td><td class=\"w2p_fw\">United Kingdom</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_capital__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_capital\" id=\"places_capital__label\">Capital: </label></td><td class=\"w2p_fw\">London</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_continent__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_continent\" id=\"places_continent__label\">Continent: </label></td><td class=\"w2p_fw\"><a href=\"/places/default/continent/EU\">EU</a></td><td class=\"w2p_fc\"></td></tr><tr id=\"places_tld__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_tld\" id=\"places_tld__label\">Tld: </label></td><td class=\"w2p_fw\">.uk</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_currency_code__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_currency_code\" id=\"places_currency_code__label\">Currency Code: </label></td><td class=\"w2p_fw\">GBP</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_currency_name__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_currency_name\" id=\"places_currency_name__label\">Currency Name: </label></td><td class=\"w2p_fw\">Pound</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_phone__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_phone\" id=\"places_phone__label\">Phone: </label></td><td class=\"w2p_fw\">44</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_postal_code_format__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_postal_code_format\" id=\"places_postal_code_format__label\">Postal Code Format: </label></td><td class=\"w2p_fw\">@# #@@|@## #@@|@@# #@@|@@## #@@|@#@ #@@|@@#@ #@@|GIR0AA</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_postal_code_regex__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_postal_code_regex\" id=\"places_postal_code_regex__label\">Postal Code Regex: </label></td><td class=\"w2p_fw\">^(([A-Z]\\d{2}[A-Z]{2})|([A-Z]\\d{3}[A-Z]{2})|([A-Z]{2}\\d{2}[A-Z]{2})|([A-Z]{2}\\d{3}[A-Z]{2})|([A-Z]\\d[A-Z]\\d[A-Z]{2})|([A-Z]{2}\\d[A-Z]\\d[A-Z]{2})|(GIR0AA))$</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_languages__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_languages\" id=\"places_languages__label\">Languages: </label></td><td class=\"w2p_fw\">en-GB,cy-GB,gd</td><td class=\"w2p_fc\"></td></tr><tr id=\"places_neighbours__row\"><td class=\"w2p_fl\"><label class=\"readonly\" for=\"places_neighbours\" id=\"places_neighbours__label\">Neighbours: </label></td><td class=\"w2p_fw\"><div><a href=\"/places/default/iso/IE\">IE </a></div></td><td class=\"w2p_fc\"></td></tr></table><div style=\"display:none;\"><input name=\"id\" type=\"hidden\" value=\"2551487\" /></div></form>\n",
      "\n",
      "<a href=\"/places/default/edit/United-Kingdom-239\">Edit</a>\n",
      "\n",
      "            \n",
      "        </div>\n",
      "\n",
      "        \n",
      "    </section><!--/main-->\n",
      "\n",
      "    <!-- Footer ================================================== -->\n",
      "    <div class=\"row\">\n",
      "        <footer class=\"footer span12\" id=\"footer\">\n",
      "        </footer>\n",
      "    </div>\n",
      "\n",
      "  </div> <!-- /container -->\n",
      "\n",
      "  <!-- The javascript =============================================\n",
      "       (Placed at the end of the document so the pages load faster) -->\n",
      "  <script src=\"/places/static/js/bootstrap.min.js\"></script>\n",
      "  <script src=\"/places/static/js/web2py_bootstrap.js\"></script>\n",
      "  <!--[if lt IE 7 ]>\n",
      "      <script src=\"/places/static/js/dd_belatedpng.js\"></script>\n",
      "      <script> DD_belatedPNG.fix('img, .png_bg'); //fix any <img> or .png_bg background-images </script>\n",
      "      <![endif]-->\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "<class 'str'>\n",
      "<class 'lxml.html.HtmlElement'>\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "html = download('http://example.webscraping.com/places/default/view/United-Kingdom-239')\n",
    "print(html)\n",
    "print(type(html))\n",
    "tree = lxml.html.fromstring(html)\n",
    "print(type(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder init func.\n"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        print(\"I am in dunder init func.\")\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "    \n",
    "t = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before t\n",
      "I am in dunder init func.\n",
      "after t and before t1\n",
      "I am in dunder init func.\n",
      "I am in dunder call func.\n",
      "after t1 and before t2\n",
      "I am in dunder init func.\n",
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        print(\"I am in dunder init func.\")\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "\n",
    "print(\"before t\")\n",
    "t = test()\n",
    "print(\"after t and before t1\")\n",
    "t1 = test()\n",
    "t1.__call__(3, 4)\n",
    "print(\"after t1 and before t2\")\n",
    "t2 = test()\n",
    "t2(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338768864872"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338768378120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338768864984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338768866696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"hello\"\n",
    "b = a\n",
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338768866696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder init func.\n",
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        print(\"I am in dunder init func.\")\n",
    "        return None\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in dunder call func.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() should return None, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-66373ca54bfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() should return None, not 'str'"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        return \"hello\"\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        print(\"I am in dunder call func.\")\n",
    "        return x + y\n",
    "\n",
    "t = test()\n",
    "t(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunder init func in class A.\n",
      "-----------\n",
      "Dunder init func in class B.\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Dunder init func in class A.\")\n",
    "        \n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Dunder init func in class B.\")\n",
    "        \n",
    "a = A()\n",
    "print(\"-----------\")\n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunder init func in class A.\n",
      "-----------\n",
      "Dunder init func in class A.\n",
      "Dunder init func in class B.\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Dunder init func in class A.\")\n",
    "        \n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Dunder init func in class B.\")\n",
    "        \n",
    "a = A()\n",
    "print(\"-----------\")\n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunder init func in class A.\n",
      "-----------\n",
      "Dunder init func in class B.\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Dunder init func in class A.\")\n",
    "        \n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super(A).__init__()\n",
    "        print(\"Dunder init func in class B.\")\n",
    "        \n",
    "a = A()\n",
    "print(\"-----------\")\n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunder init func in class A.\n",
      "-----------\n",
      "Dunder init func in class A.\n",
      "Dunder init func in class B.\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Dunder init func in class A.\")\n",
    "        \n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Dunder init func in class B.\")\n",
    "        \n",
    "a = A()\n",
    "print(\"-----------\")\n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[8:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[len(s):len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'e', 'f', 'g']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'e', 'f', 'g']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3:len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunder init func of A\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"dunder init func of A\")\n",
    "        \n",
    "    def add(self, x, y, author):\n",
    "        self.author = YWH\n",
    "        return x + y\n",
    "    \n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A' object has no attribute 'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a57ca4b870e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'A' object has no attribute 'author'"
     ]
    }
   ],
   "source": [
    "a.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunder init func of A\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"dunder init func of A\")\n",
    "        \n",
    "    def add(self, x, y):\n",
    "        return x + y\n",
    "    \n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunder init func of A\n",
      "dunder init func of B\n"
     ]
    }
   ],
   "source": [
    "class B(A):\n",
    "    def __init__(self):\n",
    "        A.__init__(self)\n",
    "        print(\"dunder init func of B\")\n",
    "        \n",
    "    def subtraction(self, x, y):\n",
    "        return x - y\n",
    "    \n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunder init func of A\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"dunder init func of A\")\n",
    "        \n",
    "    def add(self, x, y):\n",
    "        return x + y\n",
    "    \n",
    "    def max_number(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if (self.x - self.y) >= 0:\n",
    "            return self.x\n",
    "        else:\n",
    "            return self.y\n",
    "    \n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunder init func of A\n",
      "dunder init func of B\n"
     ]
    }
   ],
   "source": [
    "class B(A):\n",
    "    def __init__(self):\n",
    "        A.__init__(self)\n",
    "        print(\"dunder init func of B\")\n",
    "        \n",
    "    def subtraction(self, x, y):\n",
    "        return x - y\n",
    "    \n",
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.max_number(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add',\n",
       " 'max_number']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__func__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a.max_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DefragResult',\n",
       " 'DefragResultBytes',\n",
       " 'MAX_CACHE_SIZE',\n",
       " 'ParseResult',\n",
       " 'ParseResultBytes',\n",
       " 'Quoter',\n",
       " 'ResultBase',\n",
       " 'SplitResult',\n",
       " 'SplitResultBytes',\n",
       " '_ALWAYS_SAFE',\n",
       " '_ALWAYS_SAFE_BYTES',\n",
       " '_DefragResultBase',\n",
       " '_NetlocResultMixinBase',\n",
       " '_NetlocResultMixinBytes',\n",
       " '_NetlocResultMixinStr',\n",
       " '_ParseResultBase',\n",
       " '_ResultMixinBytes',\n",
       " '_ResultMixinStr',\n",
       " '_SplitResultBase',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_asciire',\n",
       " '_coerce_args',\n",
       " '_decode_args',\n",
       " '_encode_result',\n",
       " '_hexdig',\n",
       " '_hextobyte',\n",
       " '_hostprog',\n",
       " '_implicit_encoding',\n",
       " '_implicit_errors',\n",
       " '_noop',\n",
       " '_parse_cache',\n",
       " '_portprog',\n",
       " '_safe_quoters',\n",
       " '_splitnetloc',\n",
       " '_splitparams',\n",
       " '_typeprog',\n",
       " 'clear_cache',\n",
       " 'collections',\n",
       " 'namedtuple',\n",
       " 'non_hierarchical',\n",
       " 'parse_qs',\n",
       " 'parse_qsl',\n",
       " 'quote',\n",
       " 'quote_from_bytes',\n",
       " 'quote_plus',\n",
       " 're',\n",
       " 'scheme_chars',\n",
       " 'splitattr',\n",
       " 'splithost',\n",
       " 'splitnport',\n",
       " 'splitpasswd',\n",
       " 'splitport',\n",
       " 'splitquery',\n",
       " 'splittag',\n",
       " 'splittype',\n",
       " 'splituser',\n",
       " 'splitvalue',\n",
       " 'sys',\n",
       " 'to_bytes',\n",
       " 'unquote',\n",
       " 'unquote_plus',\n",
       " 'unquote_to_bytes',\n",
       " 'unwrap',\n",
       " 'urldefrag',\n",
       " 'urlencode',\n",
       " 'urljoin',\n",
       " 'urlparse',\n",
       " 'urlsplit',\n",
       " 'urlunparse',\n",
       " 'urlunsplit',\n",
       " 'uses_fragment',\n",
       " 'uses_netloc',\n",
       " 'uses_params',\n",
       " 'uses_query',\n",
       " 'uses_relative']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.parse\n",
    "dir(urllib.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "d = dict(name='Bob', age=20, score=88)\n",
    "with open('dump.txt', 'wb') as f:\n",
    "    f.write(pickle.dumps(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bob', 'age': 20, 'score': 88}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('dump.txt', 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "BasicMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "BasicMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 83.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 2.7.14\n"
     ]
    }
   ],
   "source": [
    "time !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.4\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "time !py -3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
